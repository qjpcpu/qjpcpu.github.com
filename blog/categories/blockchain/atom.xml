<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: blockchain | Jason's space]]></title>
  <link href="http://qjpcpu.github.io/blog/categories/blockchain/atom.xml" rel="self"/>
  <link href="http://qjpcpu.github.io/"/>
  <updated>2018-03-05T22:47:40+08:00</updated>
  <id>http://qjpcpu.github.io/</id>
  <author>
    <name><![CDATA[Jason]]></name>
    <email><![CDATA[qjpcpu@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[以太坊交易]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/03/05/yi-tai-fang-jiao-yi/"/>
    <updated>2018-03-05T14:26:24+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/03/05/yi-tai-fang-jiao-yi</id>
    <content type="html"><![CDATA[<p>交易是区块链和重中之重,不论是简单的转账还是复杂的智能合约的执行,都是依托于交易来完成。但是我回头仔细研究了一把以太坊的交易,并梳理这篇文章的原因,仅仅是因为在面试的时候没有回答上来,羞愧……</p>

<!-- more -->

<ul id="markdown-toc">
  <li><a href="#section">交易的主要结构</a></li>
  <li><a href="#section-1">交易打包流程</a>    <ul>
      <li><a href="#section-2">拼装交易参数</a></li>
      <li><a href="#section-3">对交易签名</a></li>
      <li><a href="#section-4">是否重复交易</a></li>
      <li><a href="#section-5">验证交易参数</a></li>
      <li><a href="#section-6">丢弃低价交易</a></li>
      <li><a href="#section-7">替换重复交易(更新旧交易)</a></li>
      <li><a href="#section-8">提交交易进入交易队列</a></li>
      <li><a href="#nonce">关于交易nonce</a>        <ul>
          <li><a href="#txpoolvalidatetxnoncenonce">TxPool.validateTx()检查当前交易的<code>nonce</code>大于最新区块中账户<code>nonce</code>值</a></li>
          <li><a href="#pending">检查<code>pending</code>队列中是否有旧交易需要更新</a></li>
          <li><a href="#pendingnonce">尝试将交易加入<code>pending</code>队列时检查是否需要剔除过期的nonce</a></li>
          <li><a href="#noncependingnonce">从队列中获取所有<code>nonce</code>值小于等于账户<code>pending</code>状态的<code>nonce</code>值</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="section">交易的主要结构</h1>

<p>废话不多说,先看看交易的基础数据结构。</p>

<p>```go github.com/ethereum/go-ethereum/core/types/transaction.go
type txdata struct {
    AccountNonce uint64          <code>json:"nonce"    gencodec:"required"</code>
    Price        *big.Int        <code>json:"gasPrice" gencodec:"required"</code>
    GasLimit     uint64          <code>json:"gas"      gencodec:"required"</code>
    Recipient    *common.Address <code>json:"to"       rlp:"nil"</code> // nil means contract creation
    Amount       *big.Int        <code>json:"value"    gencodec:"required"</code>
    Payload      []byte          <code>json:"input"    gencodec:"required"</code></p>

<pre><code>// Signature values
V *big.Int `json:"v" gencodec:"required"`
R *big.Int `json:"r" gencodec:"required"`
S *big.Int `json:"s" gencodec:"required"`

// This is only used when marshaling to JSON.
Hash *common.Hash `json:"hash" rlp:"-"` } ``` * `AccountNonce`,交易发起者内部唯一标识交易的字段,避免交易双重支付 * `Price`,此交易的gas price * `GasLimit`,此交易允许的最大gas量 * `Recipient`,交易接收者,如果为`nil`说明是个合同创建交易 * `Amount`, 交易转移的`ETH`数量,单位是`wei` * `Payload`, 交易数据 * `V,R,S`, 交易签名,通过交易签名可以计算出交易发送者地址
</code></pre>

<h1 id="section-1">交易打包流程</h1>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/transaction-pkg.png" alt="pkg" /></p>

<h2 id="section-2">拼装交易参数</h2>

<p>拼装交易参数主要在<code>github.com/ethereum/go-ethereum/internal/ethapi/api.go setDefaults()</code>实现。</p>

<ul>
  <li><code>Gas</code>如果未设置,设置未默认值<code>90000</code></li>
  <li><code>GasPrice</code>如果未设置，设置为建议值</li>
  <li><code>Nonce</code>如果未设置,自动生成nonce值,该值等于当前账户nonce偏移量加上账户nonces数组长度,由此可见账户交易的nonce值是连续递增量</li>
</ul>

<h2 id="section-3">对交易签名</h2>

<p>首先使用账户的私钥对交易hash信息生成签名,注意该hash计算了包含了<code>nonce</code>值和<code>chainId</code>.</p>

<p><code>go
func (s EIP155Signer) Hash(tx *Transaction) common.Hash {
	return rlpHash([]interface{}{
		tx.data.AccountNonce,
		tx.data.Price,
		tx.data.GasLimit,
		tx.data.Recipient,
		tx.data.Amount,
		tx.data.Payload,
		s.chainId, uint(0), uint(0),
	})
}
</code></p>

<p>将签名信息的<code>0-31</code>字节放入<code>R</code>,<code>32-63</code>放入<code>S</code>,<code>64</code>放入<code>V</code>(共65字节).</p>

<p>签名完成后,开始向以太坊提交交易.注意,如果交易的<code>To</code>字段为空,说明是个合同创建交易,则自动生成合约地址,合约地址生成规则其实是<code>hash(from_addr,nonce)</code>函数:</p>

<p><code>go
// Creates an ethereum address given the bytes and the nonce
func CreateAddress(b common.Address, nonce uint64) common.Address {
    data, _ := rlp.EncodeToBytes([]interface{}{b, nonce})
    return common.BytesToAddress(Keccak256(data)[12:])
}
</code></p>

<h2 id="section-4">是否重复交易</h2>

<p>通过检查交易池里是否存在该交易hash判断是否是重复交易</p>

<p><code>go
    hash := tx.Hash()
    if pool.all[hash] != nil {
        log.Trace("Discarding already known transaction", "hash", hash)
        return false, fmt.Errorf("known transaction: %x", 
</code></p>

<h2 id="section-5">验证交易参数</h2>

<ul>
  <li>检查交易大小是否小于等于<code>32KB</code>,防止DOS攻击</li>
  <li>检查是否正确签名</li>
  <li>检查gas是否超过区块gas限制</li>
  <li>抛弃非local的且gas price偏低的交易</li>
  <li>检查nonce是否过小</li>
  <li>检查账户余额是否足够,<code>balance &gt;= gas_price * gas_limit + amount</code></li>
</ul>

<h2 id="section-6">丢弃低价交易</h2>

<p>如果交易池已满，需要将交易池中低于当前交易的踢出一个,注意踢出的交易仅限于远端交易，本地节点的交易不受影响</p>

<p>```go
// Discard finds a number of most underpriced transactions, removes them from the
// priced list and returns them for further removal from the entire pool.
func (l *txPricedList) Discard(count int, local *accountSet) types.Transactions {
    drop := make(types.Transactions, 0, count) // Remote underpriced transactions to drop
    save := make(types.Transactions, 0, 64)    // Local underpriced transactions to keep</p>

<pre><code>for len(*l.items) &gt; 0 &amp;&amp; count &gt; 0 {
    // Discard stale transactions if found during cleanup
    tx := heap.Pop(l.items).(*types.Transaction)
    if _, ok := (*l.all)[tx.Hash()]; !ok {
        l.stales--
        continue
    }
    // Non stale transaction found, discard unless local
    if local.containsTx(tx) {
        save = append(save, tx)
    } else {
        drop = append(drop, tx)
        count--
    }
}
for _, tx := range save {
    heap.Push(l.items, tx)
}
return drop } ```
</code></pre>

<h2 id="section-7">替换重复交易(更新旧交易)</h2>

<p>因为交易可以使用<code>account+nonce</code>唯一标识,所以如果发现同一账户下已存在同nonce的交易,则视为是对旧交易的一次更新,此时会使用当前交易替换掉旧交易。该机制常用于用来提升gas值避免旧交易长时间得不到处理。</p>

<h2 id="section-8">提交交易进入交易队列</h2>

<p><code>promoteExecutables()</code>将交易从待处理队列移入<code>pending</code>队列</p>

<ul>
  <li>丢弃过旧的交易,过旧的定义是<code>nonce</code>小于当前账户<code>nonce</code>值的交易</li>
  <li>丢弃低余额(账户余额不足以支持交易gas燃烧)</li>
  <li>丢弃超过账户数量限额的交易</li>
  <li>…</li>
</ul>

<p>在一系列交易控制之后,将交易写入<code>pending</code>队列,此时交易真正可被矿工打包到区块中。</p>

<h2 id="nonce">关于交易nonce</h2>

<p>流程中涉及到<code>nonce</code>的几个地方:</p>

<h4 id="txpoolvalidatetxnoncenonce">TxPool.validateTx()检查当前交易的<code>nonce</code>大于最新区块中账户<code>nonce</code>值</h4>

<p><code>go
// Ensure the transaction adheres to nonce ordering
if pool.currentState.GetNonce(from) &gt; tx.Nonce() {
	return ErrNonceTooLow
}
</code></p>

<h4 id="pending">检查<code>pending</code>队列中是否有旧交易需要更新</h4>

<p><code>go
if list := pool.pending[from]; list != nil &amp;&amp; list.Overlaps(tx) {
   ...
}
</code></p>

<p><code>Overlaps()</code>函数即根据<code>account,nonce</code>参数对进行重复检测</p>

<h4 id="pendingnonce">尝试将交易加入<code>pending</code>队列时检查是否需要剔除过期的nonce</h4>

<p><code>go
// 检查并剔除小于最新区块的交易
for _, tx := range list.Forward(pool.currentState.GetNonce(addr)) {
   ...
}
</code></p>

<h4 id="noncependingnonce">从队列中获取所有<code>nonce</code>值小于等于账户<code>pending</code>状态的<code>nonce</code>值</h4>

<p><code>go
for _, tx := range list.Ready(pool.pendingState.GetNonce(addr)) {
   ...
}
</code></p>

<p>另外,</p>

<ul>
  <li>本地节点low gas的交易并不会被丢弃</li>
  <li>如果nonce出现”空洞”,则空洞后的交易将无法打包</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入ethereum源码-从区块头看共识挖矿]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/02/24/shen-ru-ethereumyuan-ma-cong-qu-kuai-tou-kan-gong-shi-wa-kuang/"/>
    <updated>2018-02-24T16:09:11+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/02/24/shen-ru-ethereumyuan-ma-cong-qu-kuai-tou-kan-gong-shi-wa-kuang</id>
    <content type="html"><![CDATA[<p>区块是区块链的基本组成单位,而区块头又是区块的核心数据,本文希望从区块头延展开来,看看区块链的挖矿机制。</p>

<!-- more -->

<ul id="markdown-toc">
  <li><a href="#section">区块头的基本数据结构</a></li>
  <li><a href="#section-1">结构信息</a></li>
  <li><a href="#section-2">挖矿基础信息</a></li>
  <li><a href="#section-3">状态信息</a></li>
  <li><a href="#section-4">挖矿难度控制</a></li>
  <li><a href="#pow">PoW参数</a>    <ul>
      <li><a href="#dag">DAG</a></li>
      <li><a href="#hashimoto">hashimoto</a></li>
    </ul>
  </li>
  <li><a href="#section-5">其他</a></li>
  <li><a href="#section-6">参考文献</a></li>
</ul>

<h1 id="section">区块头的基本数据结构</h1>

<p>废话不多说,直接看代码:</p>

<p>```go github.com/ethereum/go-ethereum/core/types/block.go
// Header represents a block header in the Ethereum blockchain.
type Header struct {
    // 1.结构信息
    ParentHash  common.Hash    <code>json:"parentHash"       gencodec:"required"</code>
    UncleHash   common.Hash    <code>json:"sha3Uncles"       gencodec:"required"</code>
    Number      *big.Int       <code>json:"number"           gencodec:"required"</code></p>

<pre><code>// 2.挖矿基础信息
Coinbase    common.Address `json:"miner"            gencodec:"required"`
GasLimit    uint64         `json:"gasLimit"         gencodec:"required"`
GasUsed     uint64         `json:"gasUsed"          gencodec:"required"`

// 3.状态信息
Time        *big.Int       `json:"timestamp"        gencodec:"required"`
Root        common.Hash    `json:"stateRoot"        gencodec:"required"`
TxHash      common.Hash    `json:"transactionsRoot" gencodec:"required"`
ReceiptHash common.Hash    `json:"receiptsRoot"     gencodec:"required"`
Bloom       Bloom          `json:"logsBloom"        gencodec:"required"`

// 4.挖矿难度控制
Difficulty  *big.Int       `json:"difficulty"       gencodec:"required"`

// 5.PoW参数
MixDigest   common.Hash    `json:"mixHash"          gencodec:"required"`
Nonce       BlockNonce     `json:"nonce"            gencodec:"required"`

// 6.其他
Extra       []byte         `json:"extraData"        gencodec:"required"` } ```
</code></pre>

<p>乍一看区块头的字段非常多,别着急,接下来我们逐个分析。按照字段的作用,我们可以将这些字段分成6大类(如代码注释所示),分别控制结构、状态、挖矿等信息,下面我们依次查看.</p>

<blockquote>
  <p>本文引用源码大部分均位于miner/consensus两个包中,代码引用均会给出文件名</p>
</blockquote>

<h1 id="section-1">结构信息</h1>

<p>1.<code>ParentHash</code></p>

<p>简单来说,区块链其实是一个单向链表。那么单向链表中必然存在一个将链表串起来的指针,这个指针在区块链里就是<code>ParentHash</code>.每个新挖出来的区块都包含了父区块的hash值,这样我们就可以从当前区块一直溯源到创世区块,创世区块hash值为<code>0x00</code>.</p>

<p>2.<code>UncleHash</code></p>

<p>类似ParentHash,指向叔区块hash值。</p>

<p>3.<code>Number</code></p>

<p>用于标记当前区块高度,子区块高度一定是父区块+1.</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/blockchain-link.png" alt="blockchain-link" /></p>

<p>构建区块的代码包含在<code>commitNewWork</code>函数中,该函数其实就是挖矿主流程所在位置。</p>

<p><code>go github.com/ethereum/go-ethereum/miner/worker.go
func (self *worker) commitNewWork(){
    ...
    num := parent.Number()
    header := &amp;types.Header{
        ParentHash: parent.Hash(),          // 父区块的hash
        Number:     num.Add(num, common.Big1),  // 父区块的number+1
        GasLimit:   core.CalcGasLimit(parent),
        Extra:      self.extra,
        Time:       big.NewInt(tstamp),
    }
    ...
}
</code></p>

<h1 id="section-2">挖矿基础信息</h1>

<p>1.<code>Coinbase</code></p>

<p>区块链中矿工没挖出一个新区块,都会得到两部分奖励收益:挖矿奖励+手续费,那么这个奖励是到哪个账户的,就是这个coinbase帐号,默认通常是矿工本地第一个账户。</p>

<p>2.<code>GasUsed</code></p>

<p>实际使用的gas,每执行一笔交易往该字段上累积gas值,具体代码可查看<code>ethereum/go-ethereum/core/state_processor.go:ApplyTransaction</code>.</p>

<p>3.<code>GasLimit</code></p>

<p>矿工执行交易的上限gas用量,如果执行某个交易时发现gas使用超过这个值则放弃执行后续交易。其数值是基于父区块gas用量来调整,如果<code>parentGasUsed &gt; parentGasLimit * (2/3)</code>,则增大该数值，反之则减小。具体实现可参考下面代码实现。</p>

<p>```go github.com/ethereum/go-ethereum/core/block_validator.go
// CalcGasLimit computes the gas limit of the next block after parent.
// This is miner strategy, not consensus protocol.
func CalcGasLimit(parent *types.Block) uint64 {
    // contrib = (parentGasUsed * 3 / 2) / 1024
    contrib := (parent.GasUsed() + parent.GasUsed()/2) / params.GasLimitBoundDivisor</p>

<pre><code>// decay = parentGasLimit / 1024 -1
decay := parent.GasLimit()/params.GasLimitBoundDivisor - 1

/*
    strategy: gasLimit of block-to-mine is set based on parent's
    gasUsed value.  if parentGasUsed &gt; parentGasLimit * (2/3) then we
    increase it, otherwise lower it (or leave it unchanged if it's right
    at that usage) the amount increased/decreased depends on how far away
    from parentGasLimit * (2/3) parentGasUsed is.
*/
limit := parent.GasLimit() - decay + contrib
if limit &lt; params.MinGasLimit {
    limit = params.MinGasLimit
}
// however, if we're now below the target (TargetGasLimit) we increase the
// limit as much as we can (parentGasLimit / 1024 -1)
if limit &lt; params.TargetGasLimit {
    limit = parent.GasLimit() + decay
    if limit &gt; params.TargetGasLimit {
        limit = params.TargetGasLimit
    }
}
return limit } ```
</code></pre>

<h1 id="section-3">状态信息</h1>

<p>1.<code>Time</code></p>

<p>新区块的出块时间(按代码描述,严格来说其实是开始挖矿的时间)。</p>

<p>2.<code>Root</code>,<code>TxHash</code>,<code>ReceiptHash</code></p>

<p>这三个hash值对验证区块意义重大.</p>

<p><code>Root</code>代表的区块链当前所有账户的状态,<code>TxHash</code>是本区块所有交易摘要,<code>ReceiptHash</code>是本区块所有收据的摘要。</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/merkle.png" alt="merkle" /></p>

<p>这几个值都是MPT树的root hash值,只要树中任意节点数据有更改，那么这个root hash必然会跟着更改,这就为轻钱包实现提供了可能:不需要下载整个区块的数据,仅使用区块头就可以验证区块的合法性。具体说来,它允许轻客户端轻松地进行并核实以下类型的查询答案:</p>

<p>这笔交易被包含在特定的区块中了么？</p>

<ul>
  <li>
    <p>告诉我这个地址在过去30天中，发出X类型事件的所有实例（例如，一个众筹合约完成了它的目标）</p>
  </li>
  <li>
    <p>目前我的账户余额是多少？</p>
  </li>
  <li>
    <p>这个账户是否存在？</p>
  </li>
  <li>
    <p>假装在这个合约中运行这笔交易，它的输出会是什么？</p>
  </li>
</ul>

<p>第一种是由交易树（transaction tree）来处理的；第三和第四种则是由状态树（state tree）负责处理，第二种则由收据树（receipt tree）处理。计算前四个查询任务是相当简单的。服务器简单地找到对象，获取默克尔分支，并通过分支来回复轻客户端。</p>

<p>第五种查询任务同样也是由状态树处理，但它的计算方式会比较复杂。这里，我们需要构建下我们称之为默克尔状态转变的证明（Merkle state transition proof）。从本质上来讲，这样的证明也就是在说“如果你在根S的状态树上运行交易T，其结果状态树将是根为S’，log为L，输出为O” （“输出”作为存在于以太坊的一种概念，因为每一笔交易都是一个函数调用，它在理论上并不是必要的）。</p>

<p>为了推断这个证明，服务器在本地创建了一个假的区块，将状态设为 S，并假装是一个轻客户端，同时请求这笔交易。也就是说，如果请求这笔交易的过程，需要客户端确定一个账户的余额，这个轻客户端会发出一个余额疑问。如果这个轻客户端需要检查存储在一个特定合约的特定项目，该轻客户端会对此发出针对查询。服务器会正确地“回应”它所有的查询，但服务器也会跟踪它所有发回的数据。然后，服务器会把综合数据发送给客户端。客户端会进行相同的步骤，但会使用它的数据库所提供的证明。如果它的结果和服务器要求的是相同的，那客户端就接受证明。</p>

<blockquote>
  <p>MPT树可以参考文章<a href="http://ethfans.org/posts/Merkle-Patricia-Tree">Merkle树</a></p>
</blockquote>

<p>3.<code>Bloom</code></p>

<p>区块头里的布隆过滤器是用于搜索收据而构建的。</p>

<blockquote>
  <p><a href="https://github.com/cpselvis/zhihu-crawler/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0">布隆过滤器</a></p>
</blockquote>

<h1 id="section-4">挖矿难度控制</h1>

<p>1.<code>Difficulty</code></p>

<p>以太坊的挖矿难度是动态调整的,它的难度调整仅和父区块和本区块挖矿时间有关。 而该函数实现里根据启动参数目前有三种难度调整方案:</p>

<p><code>go github.com/ethereum/go-ethereum/consensus/ethash/consensus.go
func CalcDifficulty(config *params.ChainConfig, time uint64, parent *types.Header) *big.Int {
    next := new(big.Int).Add(parent.Number, big1)
    switch {
    case config.IsByzantium(next):
        return calcDifficultyByzantium(time, parent)
    case config.IsHomestead(next):
        return calcDifficultyHomestead(time, parent)
    default:
        return calcDifficultyFrontier(time, parent)
    }
}
</code></p>

<p>每种策略代码这里不具体展开,总的来说难度值的计算是这样的:</p>

<p><code>
本区块难度 = 父区块难度 + 难度调整值 + 难度炸弹
难度调整值 = f(父区块难度,父区块产生时间,本区块产生时间)
难度炸弹 = 2^(区块号/100000 - 2)
</code></p>

<p>以太坊的区块难度以单个区块为单位进行调整，可以非常迅速的适应算力的变化，正是这种机制，使以太坊在硬分叉出以太坊经典(ETC)以后没有出现比特币分叉出比特币现金(BCC)后的算力“暴击”问题。同时，以太坊的新区块难度在老区块的基础上有限调整的机制也使区块难度不会出现非常大的跳变</p>

<p>从这个公式可以看出,区块难度短期内仅和难度调整值有关(因为难度炸弹只有每100000个区块才会产生跳变),但是当挖矿到5400000区块后,难度值跳变到非常大,这个时候就不再适合挖矿。 </p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/eth-diff.jpg" alt="eth-diff" /></p>

<h1 id="pow">PoW参数</h1>

<p>接下来的两个参数就和无人不知无人不晓的工作量证明息息相关了,以太坊的工作量证明最终拼的就是谁最先得到这两个参数:<code>MixDigest</code>和<code>Nonce</code>.</p>

<p>目前以太坊线上使用的共识算法是基于PoW的ethash算法,主要实现位于<code>github.com/ethereum/go-ethereum/consensus/ethash</code>包中。</p>

<p>PoW算法的思路都大致是相似的,通过暴力枚举猜测一个nonce值,使得根据这个nonce种子计算出的hash值符合约定的难度,这个难度其实就是要求hash值前缀包含多少个0. </p>

<p>目前以太坊使用的hash是256位,所以将难度折算成前缀0的位数就是:<code>bits0 = (2^256)/difficulty</code>,那么我们的代码不停枚举nonce然后将计算得到的hash值前缀0位数和这个做比较就行了,主逻辑代码如下:</p>

<p><code>go 
func (ethash *Ethash) mine(block *types.Block, id int, seed uint64, abort chan struct{}, found chan *types.Block) {
    // Extract some data from the header
    var (
        header  = block.Header()
        hash    = header.HashNoNonce().Bytes()
        // 将难度转换得出前缀0的位数
        target  = new(big.Int).Div(maxUint256, header.Difficulty)
        number  = header.Number.Uint64()
        dataset = ethash.dataset(number)
    )
    ...
search:
    for {
        ...
            // Compute the PoW value of this nonce
            digest, result := hashimotoFull(dataset.dataset, hash, nonce)
            if new(big.Int).SetBytes(result).Cmp(target) &lt;= 0 {
                // Correct nonce found, create a new header with it
                header = types.CopyHeader(header)
                header.Nonce = types.EncodeNonce(nonce)
                header.MixDigest = common.BytesToHash(digest)
                ...
            }
            nonce++
         ...
    }
}
</code></p>

<p>该函数首先计算出区块难度对应的前缀0位数<code>target</code>,然后生成PoW依赖的计算数据集<code>dataset = ethash.dataset(number)</code>,最终开始死循环尝试计算<code>digest, result := hashimotoFull(dataset.dataset, hash, nonce)</code>,得到结果后将这两个随机数据赋值到区块头对应字段去。</p>

<p>当这个区块成功挖出后，别的区块很容易验证这个区块的PoW是否有效,就使用同样方法产生计算数据集<code>dataset</code>,然后调用<code>hashimotoLight(和hashimotoFull基本一致)</code>计算出<code>digest</code>和区块头的<code>MixDigest</code>做比较就可以了。</p>

<p>这里我们跳过了两个重要的步骤:</p>

<p>a.依赖数据集<code>dataset</code>的生成实现
b.<code>hashimotoFull/hashimotoLight</code>的具体实现</p>

<p>依赖数据集的生成就要说到以太坊的DAG</p>

<h2 id="dag">DAG</h2>

<p>ethash将DAG（有向非循环图）用于工作量证明算法，这是为每个epoch(<code>epoch := block / epochLength</code>)生成，例如，每3000个区块（125个小时，大约5.2天）。DAG要花很长时间生成。如果客户端只是按需要生成它，那么在找到新epoch第一个区块之前，每个epoch过渡都要等待很长时间。然而，DAG只取决于区块数量，所以可以预先计算来避免在每个epoch过渡过长的等待时间。Geth和ethminer执行自动的DAG生成，每次维持2个DAG以便epoch过渡流畅。挖矿从控制台操控的时候，自动DAG生成会被打开和关闭。</p>

<h2 id="hashimoto">hashimoto</h2>

<blockquote>
  <p>下面的描述摘自<a href="http://blog.csdn.net/teaspring/article/details/78050274">挖矿和共识算法的奥秘</a></p>
</blockquote>

<p>hashimoto()的逻辑比较复杂，包含了多次、多种哈希运算。下面尝试从其中数据结构变化的角度来简单描述之：</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/consensus.png" alt="hashimoto" /></p>

<p>简单介绍一下上图所代表的代码流程：</p>

<ul>
  <li>首先，hashimoto()函数将入参@hash和@nonce合并成一个40 bytes长的数组，取它的SHA-512哈希值取名seed，长度为64 bytes。</li>
  <li>然后，将seed[]转化成以uint32为元素的数组mix[]，注意一个uint32数等于4 bytes，故而seed[]只能转化成16个uint32数，而mix[]数组长度32，所以此时mix[]数组前后各半是等值的。</li>
  <li>接着，lookup()函数登场。用一个循环，不断调用lookup()从外部数据集中取出uint32元素类型数组，向mix[]数组中混入未知的数据。循环的次数可用参数调节，目前设为64次。每次循环中，变化生成参数index，从而使得每次调用lookup()函数取出的数组都各不相同。这里混入数据的方式是一种类似向量“异或”的操作，来自于FNV算法。</li>
  <li>待混淆数据完成后，得到一个基本上面目全非的mix[]，长度为32的uint32数组。这时，将其折叠(压缩)成一个长度缩小成原长1/4的uint32数组，折叠的操作方法还是来自FNV算法。</li>
  <li>最后，将折叠后的mix[]由长度为8的uint32型数组直接转化成一个长度32的byte数组，这就是返回值@digest；同时将之前的seed[]数组与digest合并再取一次SHA-256哈希值，得到的长度32的byte数组，即返回值@result。</li>
</ul>

<p>最终经过一系列多次、多种的哈希运算，hashimoto()返回两个长度均为32的byte数组 - digest[]和result[]。回忆一下ethash.mine()函数中，对于hashimotoFull()的两个返回值，会直接以big.int整型数形式比较result和target；如果符合要求，则将digest取SHA3-256的哈希值(256 bits)，并存于Header.MixDigest中，待以后Ethash.VerifySeal()可以加以验证。</p>

<h1 id="section-5">其他</h1>

<p>1.<code>Extra</code></p>

<h1 id="section-6">参考文献</h1>

<ul>
  <li><a href="http://blog.csdn.net/teaspring/article/details/78050274">挖矿和共识算法的奥秘</a> </li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入ethereum源码-whisper协议解读]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/02/07/shen-ru-ethereumyuan-ma-whisperxie-yi-jie-du/"/>
    <updated>2018-02-07T16:13:02+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/02/07/shen-ru-ethereumyuan-ma-whisperxie-yi-jie-du</id>
    <content type="html"><![CDATA[<p>whisper协议是以太坊DApps之间的通信协议。</p>

<!-- more -->

<h1 id="section">概述</h1>

<p>whisper是完全基于<code>ID</code>的消息系统,它的设计目的是形成一套p2p节点间的异步广播系统。whisper网络上的消息是加密传送的,完全可以暴露在公网进行传输;此外,为了防范<code>DDos</code>攻击,whisper使用了<code>proof-of-work(PoW)</code>工作量证明提高消息发送门槛。</p>

<h1 id="whisper">whisper基础构件</h1>

<p>whisper协议对上层暴露出一套类似于<code>订阅-发布</code>的API模型,节点可以申请自己感兴趣的<code>topic</code>，那么就只会接收到这些<code>topic</code>的消息,无关主题的消息将被丢弃。在这套体系内，有几个基础构件需要说明下:</p>

<h2 id="envelope">Envelope信封</h2>

<p><code>envelope即信封</code>是whisper网络节点传输数据的基本形式。信封包含了加密的数据体和明文的元数据,元数据主要用于基本的消息校验和消息体的解密。</p>

<p>信封是以RLP编码的格式传输:</p>

<p><code>
[ Version, Expiry, TTL, Topic, AESNonce, Data, EnvNonce ]
</code></p>

<ul>
  <li><code>Version</code>:最多4字节(目前仅使用了1字节)，如果信封的<code>Version</code>比本节点当前值高,将无法解密,仅做转发</li>
  <li><code>Expiry</code>:4字节（unix时间戳秒数）,过期时间</li>
  <li><code>TTL</code>:4字节,剩余存活时间秒数</li>
  <li><code>Topic</code>:4字节,信封主题</li>
  <li><code>AESNonce</code>:12字节随机数据,仅在对称加密时有效</li>
  <li><code>Data</code>:消息体</li>
  <li><code>EnvNonce</code>:8字节任意数据(用于PoW计算)</li>
</ul>

<p>如果节点无法解密信封，那么节点对信封内的消息内容一无所知，单这并不影响节点将消息进行转发扩散。</p>

<h2 id="message">Message消息</h2>

<p>信封内的消息体解密后即得到消息内容。</p>

<h2 id="topic">Topic主题</h2>

<p>每个信封上都有一个主题,注意主题可以仅使用部分前缀</p>

<h2 id="filter">Filter过滤器</h2>

<p><code>filter</code>即<code>订阅-发布</code>模型中的订阅者</p>

<h2 id="pow">PoW工作量证明</h2>

<p><code>PoW</code>的存在是为了反垃圾信息以及降低网络负担。计算PoW所付出的代价可以理解为抵扣节点为传播和存储信息锁花费的资源.</p>

<p>在<code>whisperv5</code>中,<code>PoW</code>定义为:</p>

<p><code>
PoW = (2^BestBit) / (size * TTL)
</code></p>

<ul>
  <li><code>BestBit</code>是hash计算值的前导0个数</li>
  <li><code>size</code>是消息大小</li>
  <li><code>TTL</code></li>
</ul>

<p>具有高<code>PoW</code>的消息具有优先处理权。</p>

<p>whisper节点发送消息需要经过<code>创建消息whisper.NewSentMessage()</code>—-&gt;<code>封装入信封msg.Wrap(msg)</code>—-&gt;<code>shh.Send()</code>,消息的工作量证明就在第二步装入信封的时候进行计算。</p>

<p><code>Warp</code>函数最终调用<code>Seal</code>:</p>

<p>```go github.com/ethereum/go-ethereum/whisper/whisperv5/envelope.go
func (e *Envelope) Seal(options *MessageParams) error {
    var target, bestBit int // target是需要达到的目标前置0位数
    if options.PoW == 0 {
        // 将消息过期时间调整到工作量计算完成后
        e.Expiry += options.WorkTime
    } else {
        // 根据公式 PoW = (2^BestBit) / (size * TTL) 从预设的PoW阈值反解出BestBit
        target = e.powToFirstBit(options.PoW)
        if target &lt; 1 {
            target = 1
        }
    }</p>

<pre><code>buf := make([]byte, 64)
// Keccak256是SHA-3的一种,Keccak已可以抵御最小的复杂度为2n的攻击，其中N为散列的大小。它具有广泛的安全边际。至目前为止，第三方密码分析已经显示出Keccak没有严重的弱点
h := crypto.Keccak256(e.rlpWithoutNonce())
copy(buf[:32], h)

finish := time.Now().Add(time.Duration(options.WorkTime) * time.Second).UnixNano()
for nonce := uint64(0); time.Now().UnixNano() &lt; finish; {
    for i := 0; i &lt; 1024; i++ {
        // 暴力尝试nonce值
        binary.BigEndian.PutUint64(buf[56:], nonce)
        d := new(big.Int).SetBytes(crypto.Keccak256(buf))
        firstBit := math.FirstBitSet(d)
        if firstBit &gt; bestBit {
            e.EnvNonce, bestBit = nonce, firstBit
            // 当尝试得到满足条件的EnvNonce,计算完成
            if target &gt; 0 &amp;&amp; bestBit &gt;= target {
                return nil
            }
        }
        nonce++
    }
}
if target &gt; 0 &amp;&amp; bestBit &lt; target {
    return fmt.Errorf("failed to reach the PoW target, specified pow time (%d seconds) was insufficient", options.WorkTime)
}
return nil } ```
</code></pre>

<h1 id="section-1">通信流程</h1>

<p>whisper协议的实现位于包<code>github.com/ethereum/go-ethereum/whisper</code>，该包下面有多个版本实现,目前最新协议包是<code>whisperv6</code>.</p>

<h2 id="whisper-main-loop">whisper main loop</h2>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/whisper-main-loop.png" alt="whisper-main-loop" /></p>

<p>whisper节点启动后产生两个分支:</p>

<ul>
  <li>一个分支负责清理<code>shh.envelopes</code>中的过期消息</li>
  <li>另一个分支(proccessQueue)从两个队列取出新接收到的消息,根据消息对应topic投放(Trigger)到对应接收者(filter),从而交付给上层应用进行处理</li>
</ul>

<p>补充说下whisper里两个队列<code>messageQueue,p2pMsgQueue</code>的不同作用,<code>messageQueue</code>接收普通的广播消息,<code>p2pMsgQueue</code>接收点对点的直接消息,可绕过<code>pow</code>和<code>ttl</code>限制.</p>

<h2 id="whisper-protocol">whisper protocol</h2>

<p>whisper协议的具体实现里,代码流程也非常清晰:</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/whisper-peer-loop.png" alt="whisper-peer-loop" /></p>

<p>每个peer连接成功后,产生两个goroutine,进行消息接收和广播:</p>

<ul>
  <li>接收消息协程不断从连接中读取新消息,并且将消息暂存到<code>shh.envelopes</code>中,如果发现是一条未接收过的新消息,则将消息转发到对应的队列<code>(messageQueue,p2pMsgQueue)</code></li>
  <li>广播协程负责将该peer未接收过的消息(本节点认为该peer未接收过,并非peer一定没接收过,p2p网络其他节点可能已经将消息广播到该节点了)投递到该peer</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入ethereum源码-p2p模块节点发现机制]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi/"/>
    <updated>2018-01-30T11:40:37+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi</id>
    <content type="html"><![CDATA[<p>ethereum是基于kademlia协议实现其节点自动发现机制,完整整个网络拓扑关系的构建刷新。
<!-- more --></p>

<ul id="markdown-toc">
  <li><a href="#kademlia">Kademlia协议</a></li>
  <li><a href="#kademlia-like">以太坊Kademlia-like协议</a></li>
  <li><a href="#section">源码跟踪以太坊节点发现机制</a>    <ul>
      <li><a href="#refreshloop">1. <code>refreshLoop()</code></a></li>
      <li><a href="#loopreadloop">2. <code>loop()</code>和<code>readLoop()</code></a></li>
    </ul>
  </li>
  <li><a href="#section-1">内网穿透</a></li>
  <li><a href="#section-2">参考文献</a></li>
</ul>

<h1 id="kademlia">Kademlia协议</h1>

<blockquote>
  <p>以下内容摘自维基百科,全文查看参考文献Kademlia</p>
</blockquote>

<p>Kademlia是一种通过分散式杂凑表实现的协议算法，它是由Petar和David为非集中式P2P计算机网络而设计的。Kademlia规定了网络的结构，也规定了通过节点查询进行信息交换的方式。Kademlia网络节点之间使用UDP进行通讯。参与通讯的所有节点形成一张虚拟网（或者叫做覆盖网）。这些节点通过一组数字（或称为节点ID）来进行身份标识。节点ID不仅可以用来做身份标识，还可以用来进行值定位。</p>

<p>Kademlia路由表由多个列表组成，每个列表对应节点ID的一位（例如：假如节点ID共有128位，则节点的路由表将包含128个列表），包含多个条目，条目中包含定位其他节点所必要的一些数据。列表条目中的这些数据通常是由其他节点的IP地址，端口和节点ID组成。每个列表对应于与节点相距特定范围距离的一些节点，节点的第n个列表中所找到的节点的第n位与该节点的第n位肯定不同，而前n-1位相同，这就意味着很容易使用网络中远离该节点的一半节点来填充第一个列表（第一位不同的节点最多有一半），而用网络中四分之一的节点来填充第二个列表（比第一个列表中的那些节点离该节点更近一位），依次类推。如果ID有128个二进制位，则网络中的每个节点按照不同的异或距离把其他所有的节点分成了128类，ID的每一位对应于其中的一类。随着网络中的节点被某节点发现，它们被逐步加入到该节点的相应的列表中，这个过程中包括向节点列表中存信息和从节点列表中取信息的操作，甚至还包括当时协助其他节点寻找相应键对应值的操作。这个过程中发现的所有节点都将被加入到节点的列表之中，因此节点对整个网络的感知是动态的，这使得网络一直保持着频繁地更新，增强了抵御错误和攻击的能力。</p>

<p>在Kademlia相关的论文中，列表也称为K桶，其中K是一个系统变量，如20，每一个K桶是一个最多包含K个条目的列表，也就是说，网络中所有节点的一个列表（对应于某一位，与该节点相距一个特定的距离）最多包含20个节点。随着对应的bit位变低（即对应的异或距离越来越短），K桶包含的可能节点数迅速下降（这是由于K桶对应的异或距离越近，节点数越少），因此，对应于更低bit位的K桶显然包含网络中所有相关部分的节点。由于网络中节点的实际数量远远小于可能ID号的数量，所以对应那些短距离的某些K桶可能一直是空的（如果异或距离只有1，可能的数量就最大只能为1，这个异或距离为1的节点如果没有发现，则对应于异或距离为1的K桶则是空的）。</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/63/Dht_example_SVG.svg" alt="kademlia example" /></p>

<p>让我们看上面的那个简单网络，该网络最大可有2^3，即8个关键字和节点，目前共有7个节点加入，每个节点用一个小圈表示（在树的底部）。我们考虑那个用黑圈标注的节点6，它共有3个K桶，节点0，1和2（二进制表示为000，001和010）是第一个K桶的候选节点，节点3目前（二进制表示为011）还没有加入网络，节点4和节点5（二进制表示分别为100和101）是第二个K桶的候选节点，只有节点7（二进制表示为111）是第3个K桶的候选节点。图中，3个K桶都用灰色圈表示，假如K桶的大小（即K值）是2，那么第一个K桶只能包含3个节点中的2个。众所周知，那些长时间在线连接的节点未来长时间在线的可能性更大，基于这种静态统计分布的规律，Kademlia选择把那些长时间在线的节点存入K桶，这一方法增长了未来某一时刻有效节点的数量，同时也提供了更为稳定的网络。当某个K桶已满，而又发现了相应于该桶的新节点的时候，那么，就首先检查K桶中最早访问的节点，假如该节点仍然存活，那么新节点就被安排到一个附属列表中（作为一个替代缓存）.只有当K桶中的某个节点停止响应的时候，替代cache才被使用。换句话说，新发现的节点只有在老的节点消失后才被使用。</p>

<h1 id="kademlia-like">以太坊Kademlia-like协议</h1>

<p>以太坊的kademlia网(简称kad)和标准kad网有部分差异.</p>

<p>下面对照以太坊源码,阐述下kad网里几个概念:</p>

<p><code>go github.com/ethereum/go-ethereum/p2p/discover/table.go
const (
    alpha      = 3                      // Kademlia并发参数
    bucketSize = 16                     // Kademlia K桶大小(可容纳节点数)
    hashBits   = len(common.Hash{}) * 8 // 每个节点ID长度,32*8=256, 32位16进制
    nBuckets   = hashBits + 1           // K桶个数
)
</code></p>

<ul>
  <li><code>α</code>即代码里的<code>alpha</code>,是系统内一个优化参数,控制每次从K桶最多取出节点个数,ethereum取值3</li>
  <li><code>bucketSize</code>,K桶大小,ethereum取16</li>
  <li><code>hashBits</code>,节点长度256位</li>
  <li><code>nBuckets</code>,K桶个数,目前取257</li>
</ul>

<p>以太坊Kad网总共定义了4种消息类型:</p>

<p>```go github.com/ethereum/go-ethereum/p2p/discover/udp.go
const (
    pingPacket = iota + 1 // ping操作
    pongPacket            // pong操作</p>

<pre><code>findnodePacket        // find node节点查询
neighborsPacket       // neighbors邻居回应 ) ```
</code></pre>

<p><code>ping</code>和<code>pong</code>是一对操作,用于检测节点活性,节点收到<code>ping</code>消息后立即回复<code>pong</code>响应:</p>

<p><code>go
// 收到ping消息的响应函数
func (req *ping) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {
    ...
    // 向ping消息发送方回复pong
    t.send(from, pongPacket, &amp;pong{
        To:         makeEndpoint(from, req.From.TCP),
        ReplyTok:   mac,
        Expiration: uint64(time.Now().Add(expiration).Unix()),
    })
    if !t.handleReply(fromID, pingPacket, req) {
        // 成功完成一次ping-pong,更新K桶节点信息
        go t.bond(true, fromID, from, req.From.TCP)
    }
    return nil
}
</code></p>

<p><code>findnode</code>和<code>neighbors</code>是一对操作.</p>

<p><code>findnode</code>用于查找与某节点相距最近的节点,查找到后以<code>neighbors</code>类型消息回复查找发起者</p>

<p>```go
// 收到findnode消息的响应函数
func (req *findnode) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {
    …
    target := crypto.Keccak256Hash(req.Target[:])
    …
    // 从本节点路由表里查找于target节点相距最近的bucketSize的节点
    closest := t.closest(target, bucketSize).entries
    …</p>

<pre><code>p := neighbors{Expiration: uint64(time.Now().Add(expiration).Unix())}
// 回复查询发起方
for i, n := range closest {
    ...
    t.send(from, neighborsPacket, &amp;p)
    ...
}
return nil } ```
</code></pre>

<h1 id="section">源码跟踪以太坊节点发现机制</h1>

<p>了解了以太坊的4种基本操作以及kad网络概念,我们就可以来看看节点发现机制怎么流转起来的:</p>

<p>节点发现的代码位于<code>github.com/ethereum/go-ethereum/p2p/discover</code>包。</p>

<p>首先,在节点启动时启动UDP”端口监听”:<code>server.Start() ==&gt; discover.ListenUDP ==&gt; newUDP()</code></p>

<p><code>newUDP()</code>分叉出去三个流程,三个流程均是无限循环:</p>

<ul>
  <li><code>func (tab *Table) refreshLoop()</code></li>
  <li><code>func (t *udp) loop()</code></li>
  <li><code>func (t *udp) readLoop(unhandled chan ReadPacket)</code></li>
</ul>

<h4 id="refreshloop">1. <code>refreshLoop()</code></h4>

<p>该流程每隔1小时或按需刷新K桶,核心逻辑实现位于<code>doRefresh</code>函数:</p>

<p>```go github.com/ethereum/go-ethereum/p2p/discover/table.go
func (tab *Table) doRefresh(done chan struct{}) {
    …
    // 和标准Kademlia协议选取最旧的K桶进行刷新不同，以太坊选取一个随机节点ID作为刷新基点
    var target NodeID
    rand.Read(target[:])
    // lookup函数是最kad网最核心函数,查询离target最近一批节点
    result := tab.lookup(target, false)
    if len(result) &gt; 0 {
        return
    }</p>

<pre><code>// 如果没找到,则从本地节点数据库加载预配置的种子节点到对应K桶
seeds := tab.db.querySeeds(seedCount, seedMaxAge)
seeds = tab.bondall(append(seeds, tab.nursery...))
...
// 最后,以自身作为目标节点,刷新K桶
tab.lookup(tab.self.ID, false) } ```
</code></pre>

<p><code>tab.lookup</code>函数虽然关键,然而其逻辑其实是很简单的:</p>

<p>a. 查询离target最近一批节点,距离计算即对kad网络XOR(异或)距离计算的实现</p>

<p><code>go
func (tab *Table) closest(target common.Hash, nresults int) *nodesByDistance {
    // 遍历本地路由节点表
    close := &amp;nodesByDistance{target: target}
    for _, b := range tab.buckets {
        for _, n := range b.entries {
            close.push(n, nresults)
        }
    }
    return close
}
// close.push最终调用distcmp进行异或计算
func distcmp(target, a, b common.Hash) int {
    for i := range target {
        da := a[i] ^ target[i]
        db := b[i] ^ target[i]
        if da &gt; db {
            return 1
        } else if da &lt; db {
            return -1
        }
    }
    return 0
}
</code></p>

<p>b. 迭代上一步查到的所有节点,向这些节点发起<code>findnode</code>操作查询离target节点最近的节点列表,将查询得到的节点进行<code>ping-pong</code>测试,将测试通过的节点落库保存</p>

<p>经过这个流程后,节点的K桶就能够比较均匀地将不同网络节点更新到本地K桶中。</p>

<h4 id="loopreadloop">2. <code>loop()</code>和<code>readLoop()</code></h4>

<p>这两个循环流程放在一起说,它们主要是一个工程实现,将异步调用代码通过channel串接成同步。业务上主要是负责处理<code>ping,pong,findnode,neighbors</code>四个消息类型的收发。</p>

<p>唯一值得稍加阐述的可能只有<code>pending</code>结构:</p>

<p>```go
// pending实现了一种延迟处理逻辑
//
// 它主要有两个作用:
// 1. 提供回调机制,当某一个操作发起异步请求时,就使用pending结构封装一个闭包,当收到异步回复后从pending列表取出这个闭包,执行回调,因此在这个回调里可以完成数据包校验等后处理
// 如findnode操作将更新k桶的操作暂存,再获取到异步回复后执行这个闭包完成k桶更新
// 2. 提供多个回复接收功能,一个RPC请求可能会对应多个回复包,比如findnode对应多个neigbours回复包,此时可以提供多个pending进行逐个包校验
type pending struct {
    // 来源节点
    from  NodeID
    ptype byte</p>

<pre><code>// 调用超时丢弃pending结构
deadline time.Time

// 回调函数,简单而强大
callback func(resp interface{}) (done bool)

errc chan&lt;- error } ```
</code></pre>

<p>综述,邻居节点发现流程:</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/eth_kad.jpeg" alt="kademlia" /></p>

<p>节点第一次启动读取公共种子节点信息,已本节点ID作为target更新本地K桶,然后每隔一段时间进行节点更新, 刷新K桶流程如下:</p>

<p>a. 随机生成目标节点Id，记为TargetId，从1开始记录发现次数和刷新时间。</p>

<p>b. 在当前节点的K桶里查找与目标节点最近的16个节点</p>

<p>c. 向b中得到的每个节点发送findnode命令,接收到每个节点传回的neighbours节点</p>

<p>d. 对c返回的每个节点进行ping-pong测试然后更新到本地k桶</p>

<p>e. 上述流程均是基于UDP的发现流程,p2p网络会定时随机取k桶中未连接的节点进行TCP连接,在连接好的TCP通道进行通信(tcp连接协程里会自己做心跳维护这个连接)</p>

<h1 id="section-1">内网穿透</h1>

<p>ethereum是基于p2p通信的,所有的操作都有可能涉及到内网穿透,而目前内网穿透最常用的方法是udp打洞,这也是kad网络使用udp作为基础通信协议的原因。</p>

<p>一个简单的udp打通进行p2p通信的例子讲解可以参考<a href="http://qjpcpu.github.io/blog/2018/01/29/shen-ru-ethereumyuan-ma-p2pmo-kuai-ji-chu-jie-gou/">深入ethereum源码-p2p模块基础结构</a>。</p>

<p>然而以太坊里将这部分逻辑全部隐藏,可以在节点初始化函数里看出一点痕迹:</p>

<p><code>go 
func (srv *Server) Start() (err error) {
        addr, err := net.ResolveUDPAddr("udp", srv.ListenAddr)
        if err != nil {
            return err
        }
        conn, err = net.ListenUDP("udp", addr)
        if err != nil {
            return err
        }
        realaddr = conn.LocalAddr().(*net.UDPAddr)
        if srv.NAT != nil {
            if !realaddr.IP.IsLoopback() {
                // 进行内网网端口映射
                go nat.Map(srv.NAT, srv.quit, "udp", realaddr.Port, realaddr.Port, "ethereum discovery")
            }
            // TODO: react to external IP changes over time.
            if ext, err := srv.NAT.ExternalIP(); err == nil {
                realaddr = &amp;net.UDPAddr{IP: ext, Port: realaddr.Port}
            }
        }
}
</code></p>

<p>首先，以太坊tcp/udp共用了一个端口,然后使用uPnp协议簇进行内外网端口映射,完成链路打通,从而穿透内网.</p>

<p>具体封装位于<code>nat</code>模块,但具体实现也是使用了三方库<a href="https://github.com/huin/goupnp">goupnp</a>.具体实现是关于uPnP的一个大话题,就不在这里分叉出去了。</p>

<h1 id="section-2">参考文献</h1>

<ul>
  <li><a href="https://zh.wikipedia.org/wiki/Kademlia">Kademlia</a></li>
  <li><a href="http://www.yeolar.com/note/2010/03/21/kademlia/">Kademlia协议原理简介</a></li>
  <li><a href="https://github.com/ethereum/wiki/wiki/Node-discovery-protocol">Node discovery protocol</a></li>
  <li><a href="http://www.8btc.com/etc-p2p">P2P网络及节点发现机制</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入ethereum源码-p2p模块基础结构]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/01/29/shen-ru-ethereumyuan-ma-p2pmo-kuai-ji-chu-jie-gou/"/>
    <updated>2018-01-29T11:19:23+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/01/29/shen-ru-ethereumyuan-ma-p2pmo-kuai-ji-chu-jie-gou</id>
    <content type="html"><![CDATA[<p>(go-ethereum/p2p)包允许您快速方便地将对等网络添加到任何类型的应用程序。p2p包采用模块化结构,包含p2p网络节点通信维护及新节点发现,将网络结构的基础细节封装并向上层屏蔽,并且暴露了简单接口让上层实现子协议,上层应用使用自己的附加子协议扩展p2p非常简单直接.</p>

<p>如果将以太坊的p2p类比做tcp协议,那么p2p暴露出来的子协议就类似http,使得以太坊能够在基础p2p基础上构建出whisper网络。</p>

<!-- more -->

<ul id="markdown-toc">
  <li><a href="#peer-to-peer">Peer to peer</a></li>
  <li><a href="#peer">peer接入</a></li>
  <li><a href="#rlp">数据传输格式RLP</a></li>
  <li><a href="#section">总述</a></li>
  <li><a href="#section-1">参考文献</a></li>
</ul>

<h1 id="peer-to-peer">Peer to peer</h1>

<p>在深入了解前,最好先看看基于p2p包怎么实现一个自己子协议,建立对其的直观印象</p>

<blockquote>
  <p>下面示例来基于官方[Peer to peer]wiki文档(官方文档有个小bug, ^_^),详细参考文献</p>
</blockquote>

<p>启动一个p2p节点仅需要对<code>p2p.Server</code>做一些简单配置:</p>

<p><code>go
nodekey, _ := crypto.GenerateKey()
srv := p2p.Server{
    Config: p2p.Config{
        MaxPeers:   10,
        PrivateKey: nodekey,
        Name:       "my node name",
        ListenAddr: ":30300",
        Protocols:  []p2p.Protocol{},
        NAT:        nat.Any(),   // 支持内网穿透
        Logger:     log.New(),
    },
}
</code></p>

<p>这样启动的节点仅包含了以太坊自身的基础协议:</p>

<p>要实现自己的子协议,就需要拓展<code>Protocols:  []p2p.Protocol{}</code>,实现自己的<code>p2p.Protocol</code></p>

<p><code>go
func MyProtocol() p2p.Protocol {
	return p2p.Protocol{                                                          // 1.
		Name:    "MyProtocol",                                                    // 2.
		Version: 1,                                                               // 3.
		Length:  1,                                                               // 4.
		Run:     func(peer *p2p.Peer, ws p2p.MsgReadWriter) error { return nil }, // 5.
	}
}
</code></p>

<ol>
  <li>一个子协议即一个<code>p2p.Protocol</code></li>
  <li>子协议名,需要唯一标识该子协议</li>
  <li>协议版本号,当一个子协议有多个版本时,采纳最高版本的协议</li>
  <li>该协议拥有的消息类型个数,因为p2p网络是可扩展的，因此其需要具有能够发送随意个数的信息的能力（需要携带type，在下文中我们能够看到说明）,p2p的handler需要知道应该预留多少空间以用来服务你的协议。这是也是共识信息能够通过message ID到达各个peer并实现协商的保障。我们的协议仅仅支持一种类型</li>
  <li>在你的协议主要的handler中，我们现在故意将其留空。这个peer变量是指代连接到当前节点，其携带了一些peer本身的信息。其ws变量是reader和writer允许你同该peer进行通信，如果信息能够发送到当前节点，则反之也能够从本节点发送到对端peer节点</li>
</ol>

<p>现在让我们将前面留空的handler代码实现，以让它能够同别的peer通信:</p>

<p>```go
const messageId = 0   // 1.
type Message string   // 2.</p>

<p>func msgHandler(peer *p2p.Peer, ws p2p.MsgReadWriter) error {
    for {
        msg, err := ws.ReadMsg()   // 3.
        if err != nil {            // 4.
            return err // if reading fails return err which will disconnect the peer.
        }</p>

<pre><code>    var myMessage [1]Message
    err = msg.Decode(&amp;myMessage) // 5.
    if err != nil {
        // handle decode error
        continue
    }
    
    switch myMessage[0] {
    case "foo":
        err := p2p.SendItems(ws, messageId, "bar")  // 6.
        if err != nil {
            return err // return (and disconnect) error if writing fails.
        }
     default:
         fmt.Println("recv:", myMessage)
     }
}

return nil } ```
</code></pre>

<ol>
  <li>其中有且唯一的已知信息ID；</li>
  <li>将Messages alias 为string类型；</li>
  <li>ReadMsg将一直阻塞等待，直到其收到了一条新的信息，一个错误或者EOF；</li>
  <li>如果在读取流信息的过程当中收到了一个错误，最好的解决实践是将其返回给p2p server进行处理。这种错误通常是对端节点已经断开连接；</li>
  <li>msg包括两个属性和一个decode方法
    <ol>
      <li>Code 包括了信息ID，Code == messageId (i.e.0)</li>
      <li>Payload 是信息的内容</li>
      <li>Decode(<ptr>) 是一个工具方法：取得 msg.Payload并将其解码，并将其内容设置到传入的message指针中，如果失败了则返回一个error</ptr></li>
    </ol>
  </li>
  <li>如果解码出来的信息是foo将发回一个NewMessage并用messageId标记信息类型，信息内容是bar；而bar信息在被对端收到之后将被defaultcase捕获。</li>
</ol>

<p>现在，我们将上述的所有部分整合起来，得到下面的p2p样例代码:</p>

<p>```go
package main</p>

<p>import (
	“fmt”
	“github.com/ethereum/go-ethereum/crypto”
	“github.com/ethereum/go-ethereum/log”
	“github.com/ethereum/go-ethereum/p2p”
	“github.com/ethereum/go-ethereum/p2p/discover”
	“github.com/ethereum/go-ethereum/p2p/nat”
	“net”
	“os”
)</p>

<p>const messageId = 0</p>

<p>type Message string</p>

<p>func MyProtocol() p2p.Protocol {
	return p2p.Protocol{
		Name:    “MyProtocol”,
		Version: 1,
		Length:  1,
		Run:     msgHandler,
	}
}
func main() {
	nodekey, _ := crypto.GenerateKey()
	logger := log.New()
	logger.SetHandler(log.StderrHandler)
	srv := p2p.Server{
		Config: p2p.Config{
			MaxPeers:   10,
			PrivateKey: nodekey,
			Name:       “my node name”,
			ListenAddr: “:30300”,
			Protocols:  []p2p.Protocol{MyProtocol()},
			NAT:        nat.Any(),
			Logger:     logger,
		},
	}
	if err := srv.Start(); err != nil {
		fmt.Println(err)
		os.Exit(1)
	}
	fmt.Println(“started..”, srv.NodeInfo())
	select {}
}</p>

<p>func msgHandler(peer *p2p.Peer, ws p2p.MsgReadWriter) error {
	for {
		msg, err := ws.ReadMsg()
		if err != nil {
			return err
		}</p>

<pre><code>	var myMessage [1]Message
	err = msg.Decode(&amp;myMessage)
	if err != nil {
		// handle decode error
		continue
	}

	fmt.Println("code:", msg.Code, "receiver at:", msg.ReceivedAt, "msg:", myMessage)
	switch myMessage[0] {
	case "foo":
		err := p2p.SendItems(ws, messageId, "bar")
		if err != nil {
			return err
		}
	default:
		fmt.Println("recv:", myMessage)
	}
} } ```
</code></pre>

<h1 id="peer">peer接入</h1>

<p>从上面的例子,我们可以看出来实现ethereum是非常便利的,那么下一步,我们可以看看一个节点是怎么处理新peer的接入的?梳理出这个接入过程,也就明白了节点间基本的数据流通方式.</p>

<p>首先,每个节点启动入口都在<code>func (srv *Server) Start() (err error)</code>.该函数调用<code>srv.startListening()</code>在传入的ip地址监听tcp连接:</p>

<p><code>go
func (srv *Server) startListening() error {
    // Launch the TCP listener.
    listener, err := net.Listen("tcp", srv.ListenAddr)
    ...
    go srv.listenLoop()
    ...
    // 主执行逻辑
    go srv.run(dialer)
    return nil
}
</code></p>

<p>当接收到一个新的tcp连接,节点开始检查并初始化peer</p>

<p><code>go
func (srv *Server) setupConn(c *conn, flags connFlag, dialDest *discover.Node) error {
    ...
    // 从这里开始,其实已经开始了ethereum的自有协议,doEncHandshake是RLPX协议的握手方法
    if c.id, err = c.doEncHandshake(srv.PrivateKey, dialDest); err != nil {
        srv.log.Trace("Failed RLPx handshake", "addr", c.fd.RemoteAddr(), "conn", c.flags, "err", err)
        return err
    }
    ...
    // 两次握手消息代码(handshakeMsg = 0x00)和(discMsg = 0x01)
    phs, err := c.doProtoHandshake(srv.ourHandshake)
    ...
    // 握手完毕,将新连接对象*p2p.conn压入server.addpeer
    err = srv.checkpoint(c, srv.addpeer)
    // If the checks completed successfully, runPeer has now been
    // launched by run.
    return nil
}
</code></p>

<p>下面开始看<code>Start()</code>函数里的节点主逻辑,主逻辑位于<code>Start()</code>末尾的<code>srv.run()</code>,该函数逻辑较复杂,我们现在主要看新peer接入的代码:</p>

<p>```go 
func (srv *Server) run(dialstate dialer) {
      …
      select{
          …
          case c := &lt;-srv.addpeer:  // 在这里取出之前压入addpeer的连接对象conn
          // 执行到这里表明握手完成,并且通过了节点验证
          err := srv.protoHandshakeChecks(peers, c)
          if err == nil {
              // 创建节点peer对象,传入所有子协议实现,自己实现的子协议就是在这里传入peer的,传入的所以协议通过matchProtocols函数格式化组织
              p := newPeer(c, srv.Protocols)
              …
              go srv.runPeer(p)
          }
          …
      }
      …</p>

<p>}
```</p>

<p>这里补充说一下<code>newPeer()</code>对子协议的一个组织方式:</p>

<p>```go
func matchProtocols(protocols []Protocol, caps []Cap, rw MsgReadWriter) map[string]<em>protoRW {
    // 按协议(name asc,version asc)排序子协议
    sort.Sort(capsByNameAndVersion(caps))
    // 自定义协议偏移
    offset := baseProtocolLength
    result := make(map[string]</em>protoRW)</p>

<p>outer:
    for _, cap := range caps {
        for _, proto := range protocols {
            if proto.Name == cap.Name &amp;&amp; proto.Version == cap.Version {
                // If an old protocol version matched, revert it
                if old := result[cap.Name]; old != nil {
                    offset -= old.Length
                }
                // Assign the new match
                result[cap.Name] = &amp;protoRW{Protocol: proto, offset: offset, in: make(chan Msg), w: rw}
                offset += proto.Length</p>

<pre><code>            continue outer
        }
    }
}
return result } ```
</code></pre>

<p>最终每个子协议以<code>name=&gt;protocol</code>的map格式组织起来,然后每个协议根据自身支持消息类型数量<code>Protocol.Length</code>在整个以太坊消息类型轴上占据了<code>[proto.offset,proto.offset+proto.Length)</code>的左闭右开消息类型段,理解这个结构,才好理解最终根据消息类型<code>Msg.Code</code>去找handler的逻辑(<code>func (p *Peer) getProto(code uint64) (*protoRW, error)</code>)。</p>

<p>下面继续看最终peer处理逻辑<code>srv.runPeer</code>:</p>

<p>```go
func (p *Peer) run() (remoteRequested bool, err error) {
    …
    // peer逻辑里最重要两个循环逻辑</p>

<pre><code>// 收取消息循环,核心逻辑是根据消息的代号proto, err := p.getProto(msg.Code),
// 取得对应的子协议,然后投放到对应协议的读队列proto.in &lt;- msg
go p.readLoop(readErr)
// 不停发送ping心跳包到远端peer
go p.pingLoop()

// 在startProtocols里最终调用我们自定义子协议的Run方法proto.Run(p, rw)
p.startProtocols(writeStart, writeErr)
... } ```
</code></pre>

<h1 id="rlp">数据传输格式RLP</h1>

<p>以太坊数据传输都是基于RLP编码,下面文字摘自<a href="http://ethfans.org/posts/415">RLP编码原理</a></p>

<blockquote>
  <p>RLP(Recursive Length Prefix，递归长度前缀)是一种编码算法，用于编码任意的嵌套结构的二进制数据，它是以太坊中数据序列化/反序列化的主要方法，区块、交易等数据结构在持久化时会先经过RLP编码后再存储到数据库中</p>
</blockquote>

<p>定义</p>

<blockquote>
  <p>RLP编码的定义只处理两类数据：一类是字符串（例如字节数组），一类是列表。字符串指的是一串二进制数据，列表是一个嵌套递归的结构，里面可以包含字符串和列表，例如<code>["cat",["puppy","cow"],"horse",[[]],"pig",[""],"sheep"]</code>就是一个复杂的列表。其他类型的数据需要转成以上的两类，转换的规则不是RLP编码定义的，可以根据自己的规则转换，例如struct可以转成列表，int可以转成二进制（属于字符串一类），以太坊中整数都以大端形式存储。</p>
</blockquote>

<p>这部分代码均位于<code>github.com/ethereum/go-ethereum/rlp</code>包中,代码相对独立,我也没深入研究改算法,就不详细说明了。</p>

<h1 id="section">总述</h1>

<p>本文主要梳理了以太坊p2p模块的主流程,描述了核心的peer间数据读写的来龙去脉,从代码里也能够比较容易理解以太坊子协议的概念,理清这个主干流程,以后也就能够从每个细节发散开来,深入细节。</p>

<h1 id="section-1">参考文献</h1>

<ul>
  <li><a href="https://github.com/ethereum/go-ethereum">go-ethereum github地址</a></li>
  <li><a href="https://github.com/ethereum/go-ethereum/wiki/Peer-to-Peer">Peer to Peer</a></li>
  <li><a href="http://blog.csdn.net/teaspring/article/details/78455046">基于p2p的底层通信</a></li>
  <li><a href="https://github.com/ethereum/wiki/wiki/%5B%E4%B8%AD%E6%96%87%5D-RLP">RLP</a></li>
  <li><a href="http://ethfans.org/posts/415">RLP编码原理</a></li>
</ul>
]]></content>
  </entry>
  
</feed>
