<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: blockchain | Jason's space]]></title>
  <link href="http://qjpcpu.github.io/blog/categories/blockchain/atom.xml" rel="self"/>
  <link href="http://qjpcpu.github.io/"/>
  <updated>2018-03-07T00:12:24+08:00</updated>
  <id>http://qjpcpu.github.io/</id>
  <author>
    <name><![CDATA[Jason]]></name>
    <email><![CDATA[qjpcpu@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[基于以太坊的数字资产]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/03/06/ji-yu-yi-tai-fang-de-shu-zi-zi-chan/"/>
    <updated>2018-03-06T18:24:35+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/03/06/ji-yu-yi-tai-fang-de-shu-zi-zi-chan</id>
    <content type="html"><![CDATA[<p>代币(token)是什么?</p>

<!-- more -->

<ul id="markdown-toc">
  <li><a href="#section">什么是代币</a>    <ul>
      <li><a href="#section-1">最小可用代币</a></li>
    </ul>
  </li>
  <li><a href="#erc20">ERC20</a>    <ul>
      <li><a href="#section-2">大纲</a></li>
      <li><a href="#section-3">摘要</a></li>
      <li><a href="#section-4">动机</a></li>
      <li><a href="#section-5">标准内容</a>        <ul>
          <li><a href="#section-6">方法定义</a></li>
          <li><a href="#section-7">事件定义</a></li>
          <li><a href="#section-8">范例</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#erc721">ERC721</a>    <ul>
      <li><a href="#section-9">实用性</a></li>
      <li><a href="#nft-ids">NFT IDs</a></li>
      <li><a href="#section-10">向后兼容性</a></li>
    </ul>
  </li>
  <li><a href="#section-11">其他问题</a>    <ul>
      <li><a href="#gas">自动装填gas</a></li>
    </ul>
  </li>
  <li><a href="#section-12">参考文献</a></li>
</ul>

<h1 id="section">什么是代币</h1>

<p>通常区块链上由矿工挖出的币种,我们把它称之为初代币，初代币是该区块链最底层的货币，链上的转账及各类基础交易都是以初代币作为结算依据。比如比特币对于比特币区块链，以太币之于以太坊等等。</p>

<p>而通常我们说的代币,或者token(令牌),又指的是什么呢？代币是基于区块链的智能合约定义出的二代币,如果把比特币/以太币比作tcp层的数据包，那么代币就可以类比为http层的http包，它是一个更加上层的概念。</p>

<p>目前市场上发行的代币大部分都是基于以太坊，这是因为以太坊本身是一个图灵完备的区块链，即它的智能合约语言是图灵完备语言。对比起来比特币链上的脚本是非图灵完备的。正是因为以太坊的图灵完备性，使得基于以太坊的开发者可以根据自己的业务需求设计出各种特性各异的代币,它们可以代表任何可替代的可交易商品: 虚拟货币，忠诚点，金牌，白条，游戏内物品等。</p>

<h2 id="section-1">最小可用代币</h2>

<p>标准令牌合约可能相当复杂。但实际上，一个非常基本的令牌归结为:</p>

<p>```javascript
contract MyToken {
    /* This creates an array with all balances */
    mapping (address =&gt; uint256) public balanceOf;</p>

<pre><code>/* Initializes contract with initial supply tokens to the creator of the contract */
function MyToken(uint256 initialSupply) {
    balanceOf[msg.sender] = initialSupply;              // Give the creator all initial tokens
}

/* Send coins */
function transfer(address _to, uint256 _value) {
    require(balanceOf[msg.sender] &gt;= _value);           // Check if the sender has enough
    require(balanceOf[_to] + _value &gt;= balanceOf[_to]); // Check for overflows
    balanceOf[msg.sender] -= _value;                    // Subtract from the sender
    balanceOf[_to] += _value;                           // Add the same to the recipient
} } ```
</code></pre>

<p>阅读这段代码时，请不要拘泥于<code>token</code>的字面意思。这里的<code>MyToken</code>在发行时限定了发行总额(合约构造函数),同时具备了转账功能<code>transfer</code>。那么其实他就是一个简易的货币,具备作为物物交易的中间桥梁来转移价值的能力。</p>

<h1 id="erc20">ERC20</h1>

<p>以以太坊为例，由于大家均在链上以大致相同的方式发行了各自的代币，逐渐发现其实这里面有共同的模式可以被提炼出来:由于所有代币都以标准方式实施一些基本功能，这也意味着您的代币将立即与以太坊钱包和任何其他使用相同标准的客户或合同兼容.于是就出现了<code>ERC20</code>提案。</p>

<h2 id="section-2">大纲</h2>

<p><code>
EIP: 20
Title: ERC-20 Token Standard
Author: Fabian Vogelsteller &lt;fabian@ethereum.org&gt;, Vitalik Buterin &lt;vitalik.buterin@ethereum.org&gt;
Type: Standard
Category: ERC
Status: Accepted
Created: 2015-11-19
</code></p>

<h2 id="section-3">摘要</h2>

<p>以下标准定义了在智能合约中实施代币的标准API。该标准提供了传送代币的基本功能，并允许代币被批准，以便其他链上第三方可以使用它们。</p>

<h2 id="section-4">动机</h2>

<p>标准接口允许其他应用程序重新使用以太坊上的任何令牌：从钱包到分散式交换。</p>

<h2 id="section-5">标准内容</h2>

<h3 id="section-6">方法定义</h3>

<p>```javascript
// 可选方法,返回代币名称,如MyToken
function name() constant returns (string name)
// 可选方法，返回代币符号，如EOS
function symbol() constant returns (string symbol)
// 可选方法,返回代币小数位数，如8
function decimals() constant returns (uint8 decimals)</p>

<p>// 货币总发行量
function totalSupply() constant returns (uint256 totalSupply)
// 获取某个账户的代币余额
function balanceOf(address _owner) constant returns (uint256 balance)
// (本人)向某人转账
function transfer(address _to, uint256 _value) returns (bool success)
// (本人)批准只能合约可以向某人转账
function approve(address _spender, uint256 _value) returns (bool success)
// 合约代理from向to转账(须先经过from账户approve)
function transferFrom(address _from, address _to, uint256 _value) returns (bool success)
// 查询_owner允许合约代理向_spender转账的金额
function allowance(address _owner, address _spender) constant returns (uint256 remaining)
```</p>

<h3 id="section-7">事件定义</h3>

<p><code>javascript
// 转移代币时必须触发该事件
event Transfer(address indexed _from, address indexed _to, uint256 _value)
// 批准代币时必须触发该事件
event Approval(address indexed _owner, address indexed _spender, uint256 _value)
</code></p>

<h3 id="section-8">范例</h3>

<p><a href="https://github.com/OpenZeppelin/zeppelin-solidity/blob/master/contracts/token/ERC20/StandardToken.sol">https://github.com/OpenZeppelin/zeppelin-solidity/blob/master/contracts/token/ERC20/StandardToken.sol</a>
<a href="https://github.com/ConsenSys/Tokens/blob/master/contracts/eip20/EIP20.sol">https://github.com/ConsenSys/Tokens/blob/master/contracts/eip20/EIP20.sol</a></p>

<h1 id="erc721">ERC721</h1>

<p>至于erc721的产生是为了解决数字资产唯一性问题。本质上说，erc20的两个代币之间是没有任何区别的，所以它适合作为通用的数字货币来流通，单还有一类有区别的场景，比如数字世界里我的一栋房子和你的一栋房子，他们的面积，朝向，颜色等等都会有区别，是无法同质化标识的，所以就有了erc721.</p>

<p>ERC721官方称谓是:Non-fungible Token Standard(NFT),非同质化代币标准。</p>

<p>ERC721的标准内容我这里不再详述，具体标准可以参考github上以太坊提案,实现实例的话，以太猫就是最好的代表。</p>

<h3 id="section-9">实用性</h3>

<p>许多以太坊智能合约的建议用途都依赖于跟踪单个非同质币（NFTs）。现有或计划中的NFTs 有很多，例如 Decentraland 中的 LAND，与CryptoPunks 项目同名的punks（朋克），以及Dmarket 或 EnjinCoin 等系统的游戏内物品。未来的用途包括检测真实世界中的非同质资产，例如房地产（例如 Ubitquity 或 Propy 等公司所设想的）。在这些情况下，项目在账本中不是“集中在一起的”，相反，每单位代币必须有独立的所有权并自动跟踪，这非常重要。无论这些项目的性质如何，如果我们有一个标准化的接口，并且建立跨功能的NFTs管理和销售平台，这将使得生态系统更加强大。</p>

<h3 id="nft-ids">NFT IDs</h3>

<p>该标准的基础是，每一个 NFT 在跟踪它的合约中，用唯一的一个256 位无符号整数进行标识。每个NFT 的 ID 标号在智能合约的生命周期内不允许改变。元组 ( contract address, asset ID ) 是每个特定 NFT 在以太坊生态系统中的全局唯一且完全合格的标识。虽然某些合约可能觉得 ID 从 0 开始编码，并且对于每一个新 NFT 的 ID 简单增 1 进行编码更加简便，但是使用者绝不能假设 ID 编号具有任何特定模式，并且需要将 ID 编码看做 “黑盒”。</p>

<h3 id="section-10">向后兼容性</h3>

<p>本标准尽可能遵循 ERC-20 的语义，但由于同质代币与非同质代币之间的根本差异，并不能完全兼容 ERC-20。</p>

<h1 id="section-11">其他问题</h1>

<h2 id="gas">自动装填gas</h2>

<p>每次，您在Ethereum上进行交易，您需要向该块矿工支付费用，以计算您的智能合约的结果。虽然这可能会在未来发生变化，但目前费用只能在以太网中支付，因此您的代币的所有用户都需要它。账户余额小于费用的账户被卡住，直到业主可以支付必要的费用。但在某些使用案例中，您可能不希望用户考虑以太坊，区块链或如何获得以太网，因此只要检测到平衡危险性低，您的硬币就会自动重新填充用户余额。</p>

<p>```javascript
uint minBalanceForAccounts;</p>

<p>function setMinBalance(uint minimumBalanceInFinney) onlyOwner {
     minBalanceForAccounts = minimumBalanceInFinney * 1 finney;
}
/* Send coins */
function transfer(address _to, uint256 _value) {
    …
    if(msg.sender.balance &lt; minBalanceForAccounts)
        sell((minBalanceForAccounts - msg.sender.balance) / sellPrice);
}
```</p>

<h1 id="section-12">参考文献</h1>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>[干货</td>
          <td>ERC721： Non-fungible Token Standard](http://ethfans.org/posts/eip-721-non-fungible-token-standard)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><a href="https://ethereum.org/token">Create your own CRYPTO-CURRENCY with Ethereum</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[以太坊交易]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/03/05/yi-tai-fang-jiao-yi/"/>
    <updated>2018-03-05T14:26:24+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/03/05/yi-tai-fang-jiao-yi</id>
    <content type="html"><![CDATA[<p>交易是区块链和重中之重,不论是简单的转账还是复杂的智能合约的执行,都是依托于交易来完成。但是我回头仔细研究了一把以太坊的交易,并梳理这篇文章的原因,仅仅是因为在面试的时候没有回答上来,羞愧……</p>

<!-- more -->

<ul id="markdown-toc">
  <li><a href="#section">交易的主要结构</a></li>
  <li><a href="#section-1">交易打包流程</a>    <ul>
      <li><a href="#section-2">拼装交易参数</a></li>
      <li><a href="#section-3">对交易签名</a></li>
      <li><a href="#section-4">是否重复交易</a></li>
      <li><a href="#section-5">验证交易参数</a></li>
      <li><a href="#section-6">丢弃低价交易</a></li>
      <li><a href="#section-7">替换重复交易(更新旧交易)</a></li>
      <li><a href="#section-8">提交交易进入交易队列</a></li>
      <li><a href="#nonce">关于交易nonce</a>        <ul>
          <li><a href="#txpoolvalidatetxnoncenonce">TxPool.validateTx()检查当前交易的<code>nonce</code>大于最新区块中账户<code>nonce</code>值</a></li>
          <li><a href="#pending">检查<code>pending</code>队列中是否有旧交易需要更新</a></li>
          <li><a href="#pendingnonce">尝试将交易加入<code>pending</code>队列时检查是否需要剔除过期的nonce</a></li>
          <li><a href="#noncependingnonce">从队列中获取所有<code>nonce</code>值小于等于账户<code>pending</code>状态的<code>nonce</code>值</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="section">交易的主要结构</h1>

<p>废话不多说,先看看交易的基础数据结构。</p>

<p>```go github.com/ethereum/go-ethereum/core/types/transaction.go
type txdata struct {
    AccountNonce uint64          <code>json:"nonce"    gencodec:"required"</code>
    Price        *big.Int        <code>json:"gasPrice" gencodec:"required"</code>
    GasLimit     uint64          <code>json:"gas"      gencodec:"required"</code>
    Recipient    *common.Address <code>json:"to"       rlp:"nil"</code> // nil means contract creation
    Amount       *big.Int        <code>json:"value"    gencodec:"required"</code>
    Payload      []byte          <code>json:"input"    gencodec:"required"</code></p>

<pre><code>// Signature values
V *big.Int `json:"v" gencodec:"required"`
R *big.Int `json:"r" gencodec:"required"`
S *big.Int `json:"s" gencodec:"required"`

// This is only used when marshaling to JSON.
Hash *common.Hash `json:"hash" rlp:"-"` } ``` * `AccountNonce`,交易发起者内部唯一标识交易的字段,避免交易双重支付 * `Price`,此交易的gas price * `GasLimit`,此交易允许的最大gas量 * `Recipient`,交易接收者,如果为`nil`说明是个合同创建交易 * `Amount`, 交易转移的`ETH`数量,单位是`wei` * `Payload`, 交易数据 * `V,R,S`, 交易签名,通过交易签名可以计算出交易发送者地址
</code></pre>

<h1 id="section-1">交易打包流程</h1>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/transaction-pkg.png" alt="pkg" /></p>

<h2 id="section-2">拼装交易参数</h2>

<p>拼装交易参数主要在<code>github.com/ethereum/go-ethereum/internal/ethapi/api.go setDefaults()</code>实现。</p>

<ul>
  <li><code>Gas</code>如果未设置,设置未默认值<code>90000</code></li>
  <li><code>GasPrice</code>如果未设置，设置为建议值</li>
  <li><code>Nonce</code>如果未设置,自动生成nonce值,该值等于当前账户nonce偏移量加上账户nonces数组长度,由此可见账户交易的nonce值是连续递增量</li>
</ul>

<h2 id="section-3">对交易签名</h2>

<p>首先使用账户的私钥对交易hash信息生成签名,注意该hash计算了包含了<code>nonce</code>值和<code>chainId</code>.</p>

<p><code>go
func (s EIP155Signer) Hash(tx *Transaction) common.Hash {
	return rlpHash([]interface{}{
		tx.data.AccountNonce,
		tx.data.Price,
		tx.data.GasLimit,
		tx.data.Recipient,
		tx.data.Amount,
		tx.data.Payload,
		s.chainId, uint(0), uint(0),
	})
}
</code></p>

<p>将签名信息的<code>0-31</code>字节放入<code>R</code>,<code>32-63</code>放入<code>S</code>,<code>64</code>放入<code>V</code>(共65字节).</p>

<p>签名完成后,开始向以太坊提交交易.注意,如果交易的<code>To</code>字段为空,说明是个合同创建交易,则自动生成合约地址,合约地址生成规则其实是<code>hash(from_addr,nonce)</code>函数:</p>

<p><code>go
// Creates an ethereum address given the bytes and the nonce
func CreateAddress(b common.Address, nonce uint64) common.Address {
    data, _ := rlp.EncodeToBytes([]interface{}{b, nonce})
    return common.BytesToAddress(Keccak256(data)[12:])
}
</code></p>

<h2 id="section-4">是否重复交易</h2>

<p>通过检查交易池里是否存在该交易hash判断是否是重复交易</p>

<p><code>go
    hash := tx.Hash()
    if pool.all[hash] != nil {
        log.Trace("Discarding already known transaction", "hash", hash)
        return false, fmt.Errorf("known transaction: %x", 
</code></p>

<h2 id="section-5">验证交易参数</h2>

<ul>
  <li>检查交易大小是否小于等于<code>32KB</code>,防止DOS攻击</li>
  <li>检查是否正确签名</li>
  <li>检查gas是否超过区块gas限制</li>
  <li>抛弃非local的且gas price偏低的交易</li>
  <li>检查nonce是否过小</li>
  <li>检查账户余额是否足够,<code>balance &gt;= gas_price * gas_limit + amount</code></li>
</ul>

<h2 id="section-6">丢弃低价交易</h2>

<p>如果交易池已满，需要将交易池中低于当前交易的踢出一个,注意踢出的交易仅限于远端交易，本地节点的交易不受影响</p>

<p>```go
// Discard finds a number of most underpriced transactions, removes them from the
// priced list and returns them for further removal from the entire pool.
func (l *txPricedList) Discard(count int, local *accountSet) types.Transactions {
    drop := make(types.Transactions, 0, count) // Remote underpriced transactions to drop
    save := make(types.Transactions, 0, 64)    // Local underpriced transactions to keep</p>

<pre><code>for len(*l.items) &gt; 0 &amp;&amp; count &gt; 0 {
    // Discard stale transactions if found during cleanup
    tx := heap.Pop(l.items).(*types.Transaction)
    if _, ok := (*l.all)[tx.Hash()]; !ok {
        l.stales--
        continue
    }
    // Non stale transaction found, discard unless local
    if local.containsTx(tx) {
        save = append(save, tx)
    } else {
        drop = append(drop, tx)
        count--
    }
}
for _, tx := range save {
    heap.Push(l.items, tx)
}
return drop } ```
</code></pre>

<h2 id="section-7">替换重复交易(更新旧交易)</h2>

<p>因为交易可以使用<code>account+nonce</code>唯一标识,所以如果发现同一账户下已存在同nonce的交易,则视为是对旧交易的一次更新,此时会使用当前交易替换掉旧交易。该机制常用于用来提升gas值避免旧交易长时间得不到处理。</p>

<h2 id="section-8">提交交易进入交易队列</h2>

<p><code>promoteExecutables()</code>将交易从待处理队列移入<code>pending</code>队列</p>

<ul>
  <li>丢弃过旧的交易,过旧的定义是<code>nonce</code>小于当前账户<code>nonce</code>值的交易</li>
  <li>丢弃低余额(账户余额不足以支持交易gas燃烧)</li>
  <li>丢弃超过账户数量限额的交易</li>
  <li>…</li>
</ul>

<p>在一系列交易控制之后,将交易写入<code>pending</code>队列,此时交易真正可被矿工打包到区块中。</p>

<h2 id="nonce">关于交易nonce</h2>

<p>流程中涉及到<code>nonce</code>的几个地方:</p>

<h4 id="txpoolvalidatetxnoncenonce">TxPool.validateTx()检查当前交易的<code>nonce</code>大于最新区块中账户<code>nonce</code>值</h4>

<p><code>go
// Ensure the transaction adheres to nonce ordering
if pool.currentState.GetNonce(from) &gt; tx.Nonce() {
	return ErrNonceTooLow
}
</code></p>

<h4 id="pending">检查<code>pending</code>队列中是否有旧交易需要更新</h4>

<p><code>go
if list := pool.pending[from]; list != nil &amp;&amp; list.Overlaps(tx) {
   ...
}
</code></p>

<p><code>Overlaps()</code>函数即根据<code>account,nonce</code>参数对进行重复检测</p>

<h4 id="pendingnonce">尝试将交易加入<code>pending</code>队列时检查是否需要剔除过期的nonce</h4>

<p><code>go
// 检查并剔除小于最新区块的交易
for _, tx := range list.Forward(pool.currentState.GetNonce(addr)) {
   ...
}
</code></p>

<h4 id="noncependingnonce">从队列中获取所有<code>nonce</code>值小于等于账户<code>pending</code>状态的<code>nonce</code>值</h4>

<p><code>go
for _, tx := range list.Ready(pool.pendingState.GetNonce(addr)) {
   ...
}
</code></p>

<p>另外,</p>

<ul>
  <li>本地节点low gas的交易并不会被丢弃</li>
  <li>如果nonce出现”空洞”,则空洞后的交易将无法打包</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入ethereum源码-从区块头看共识挖矿]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/02/24/shen-ru-ethereumyuan-ma-cong-qu-kuai-tou-kan-gong-shi-wa-kuang/"/>
    <updated>2018-02-24T16:09:11+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/02/24/shen-ru-ethereumyuan-ma-cong-qu-kuai-tou-kan-gong-shi-wa-kuang</id>
    <content type="html"><![CDATA[<p>区块是区块链的基本组成单位,而区块头又是区块的核心数据,本文希望从区块头延展开来,看看区块链的挖矿机制。</p>

<!-- more -->

<ul id="markdown-toc">
  <li><a href="#section">区块头的基本数据结构</a></li>
  <li><a href="#section-1">结构信息</a></li>
  <li><a href="#section-2">挖矿基础信息</a></li>
  <li><a href="#section-3">状态信息</a></li>
  <li><a href="#section-4">挖矿难度控制</a></li>
  <li><a href="#pow">PoW参数</a>    <ul>
      <li><a href="#dag">DAG</a></li>
      <li><a href="#hashimoto">hashimoto</a></li>
    </ul>
  </li>
  <li><a href="#section-5">其他</a></li>
  <li><a href="#section-6">参考文献</a></li>
</ul>

<h1 id="section">区块头的基本数据结构</h1>

<p>废话不多说,直接看代码:</p>

<p>```go github.com/ethereum/go-ethereum/core/types/block.go
// Header represents a block header in the Ethereum blockchain.
type Header struct {
    // 1.结构信息
    ParentHash  common.Hash    <code>json:"parentHash"       gencodec:"required"</code>
    UncleHash   common.Hash    <code>json:"sha3Uncles"       gencodec:"required"</code>
    Number      *big.Int       <code>json:"number"           gencodec:"required"</code></p>

<pre><code>// 2.挖矿基础信息
Coinbase    common.Address `json:"miner"            gencodec:"required"`
GasLimit    uint64         `json:"gasLimit"         gencodec:"required"`
GasUsed     uint64         `json:"gasUsed"          gencodec:"required"`

// 3.状态信息
Time        *big.Int       `json:"timestamp"        gencodec:"required"`
Root        common.Hash    `json:"stateRoot"        gencodec:"required"`
TxHash      common.Hash    `json:"transactionsRoot" gencodec:"required"`
ReceiptHash common.Hash    `json:"receiptsRoot"     gencodec:"required"`
Bloom       Bloom          `json:"logsBloom"        gencodec:"required"`

// 4.挖矿难度控制
Difficulty  *big.Int       `json:"difficulty"       gencodec:"required"`

// 5.PoW参数
MixDigest   common.Hash    `json:"mixHash"          gencodec:"required"`
Nonce       BlockNonce     `json:"nonce"            gencodec:"required"`

// 6.其他
Extra       []byte         `json:"extraData"        gencodec:"required"` } ```
</code></pre>

<p>乍一看区块头的字段非常多,别着急,接下来我们逐个分析。按照字段的作用,我们可以将这些字段分成6大类(如代码注释所示),分别控制结构、状态、挖矿等信息,下面我们依次查看.</p>

<blockquote>
  <p>本文引用源码大部分均位于miner/consensus两个包中,代码引用均会给出文件名</p>
</blockquote>

<h1 id="section-1">结构信息</h1>

<p>1.<code>ParentHash</code></p>

<p>简单来说,区块链其实是一个单向链表。那么单向链表中必然存在一个将链表串起来的指针,这个指针在区块链里就是<code>ParentHash</code>.每个新挖出来的区块都包含了父区块的hash值,这样我们就可以从当前区块一直溯源到创世区块,创世区块hash值为<code>0x00</code>.</p>

<p>2.<code>UncleHash</code></p>

<p>类似ParentHash,指向叔区块hash值。</p>

<p>3.<code>Number</code></p>

<p>用于标记当前区块高度,子区块高度一定是父区块+1.</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/blockchain-link.png" alt="blockchain-link" /></p>

<p>构建区块的代码包含在<code>commitNewWork</code>函数中,该函数其实就是挖矿主流程所在位置。</p>

<p><code>go github.com/ethereum/go-ethereum/miner/worker.go
func (self *worker) commitNewWork(){
    ...
    num := parent.Number()
    header := &amp;types.Header{
        ParentHash: parent.Hash(),          // 父区块的hash
        Number:     num.Add(num, common.Big1),  // 父区块的number+1
        GasLimit:   core.CalcGasLimit(parent),
        Extra:      self.extra,
        Time:       big.NewInt(tstamp),
    }
    ...
}
</code></p>

<h1 id="section-2">挖矿基础信息</h1>

<p>1.<code>Coinbase</code></p>

<p>区块链中矿工没挖出一个新区块,都会得到两部分奖励收益:挖矿奖励+手续费,那么这个奖励是到哪个账户的,就是这个coinbase帐号,默认通常是矿工本地第一个账户。</p>

<p>2.<code>GasUsed</code></p>

<p>实际使用的gas,每执行一笔交易往该字段上累积gas值,具体代码可查看<code>ethereum/go-ethereum/core/state_processor.go:ApplyTransaction</code>.</p>

<p>3.<code>GasLimit</code></p>

<p>矿工执行交易的上限gas用量,如果执行某个交易时发现gas使用超过这个值则放弃执行后续交易。其数值是基于父区块gas用量来调整,如果<code>parentGasUsed &gt; parentGasLimit * (2/3)</code>,则增大该数值，反之则减小。具体实现可参考下面代码实现。</p>

<p>```go github.com/ethereum/go-ethereum/core/block_validator.go
// CalcGasLimit computes the gas limit of the next block after parent.
// This is miner strategy, not consensus protocol.
func CalcGasLimit(parent *types.Block) uint64 {
    // contrib = (parentGasUsed * 3 / 2) / 1024
    contrib := (parent.GasUsed() + parent.GasUsed()/2) / params.GasLimitBoundDivisor</p>

<pre><code>// decay = parentGasLimit / 1024 -1
decay := parent.GasLimit()/params.GasLimitBoundDivisor - 1

/*
    strategy: gasLimit of block-to-mine is set based on parent's
    gasUsed value.  if parentGasUsed &gt; parentGasLimit * (2/3) then we
    increase it, otherwise lower it (or leave it unchanged if it's right
    at that usage) the amount increased/decreased depends on how far away
    from parentGasLimit * (2/3) parentGasUsed is.
*/
limit := parent.GasLimit() - decay + contrib
if limit &lt; params.MinGasLimit {
    limit = params.MinGasLimit
}
// however, if we're now below the target (TargetGasLimit) we increase the
// limit as much as we can (parentGasLimit / 1024 -1)
if limit &lt; params.TargetGasLimit {
    limit = parent.GasLimit() + decay
    if limit &gt; params.TargetGasLimit {
        limit = params.TargetGasLimit
    }
}
return limit } ```
</code></pre>

<h1 id="section-3">状态信息</h1>

<p>1.<code>Time</code></p>

<p>新区块的出块时间(按代码描述,严格来说其实是开始挖矿的时间)。</p>

<p>2.<code>Root</code>,<code>TxHash</code>,<code>ReceiptHash</code></p>

<p>这三个hash值对验证区块意义重大.</p>

<p><code>Root</code>代表的区块链当前所有账户的状态,<code>TxHash</code>是本区块所有交易摘要,<code>ReceiptHash</code>是本区块所有收据的摘要。</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/merkle.png" alt="merkle" /></p>

<p>这几个值都是MPT树的root hash值,只要树中任意节点数据有更改，那么这个root hash必然会跟着更改,这就为轻钱包实现提供了可能:不需要下载整个区块的数据,仅使用区块头就可以验证区块的合法性。具体说来,它允许轻客户端轻松地进行并核实以下类型的查询答案:</p>

<p>这笔交易被包含在特定的区块中了么？</p>

<ul>
  <li>
    <p>告诉我这个地址在过去30天中，发出X类型事件的所有实例（例如，一个众筹合约完成了它的目标）</p>
  </li>
  <li>
    <p>目前我的账户余额是多少？</p>
  </li>
  <li>
    <p>这个账户是否存在？</p>
  </li>
  <li>
    <p>假装在这个合约中运行这笔交易，它的输出会是什么？</p>
  </li>
</ul>

<p>第一种是由交易树（transaction tree）来处理的；第三和第四种则是由状态树（state tree）负责处理，第二种则由收据树（receipt tree）处理。计算前四个查询任务是相当简单的。服务器简单地找到对象，获取默克尔分支，并通过分支来回复轻客户端。</p>

<p>第五种查询任务同样也是由状态树处理，但它的计算方式会比较复杂。这里，我们需要构建下我们称之为默克尔状态转变的证明（Merkle state transition proof）。从本质上来讲，这样的证明也就是在说“如果你在根S的状态树上运行交易T，其结果状态树将是根为S’，log为L，输出为O” （“输出”作为存在于以太坊的一种概念，因为每一笔交易都是一个函数调用，它在理论上并不是必要的）。</p>

<p>为了推断这个证明，服务器在本地创建了一个假的区块，将状态设为 S，并假装是一个轻客户端，同时请求这笔交易。也就是说，如果请求这笔交易的过程，需要客户端确定一个账户的余额，这个轻客户端会发出一个余额疑问。如果这个轻客户端需要检查存储在一个特定合约的特定项目，该轻客户端会对此发出针对查询。服务器会正确地“回应”它所有的查询，但服务器也会跟踪它所有发回的数据。然后，服务器会把综合数据发送给客户端。客户端会进行相同的步骤，但会使用它的数据库所提供的证明。如果它的结果和服务器要求的是相同的，那客户端就接受证明。</p>

<blockquote>
  <p>MPT树可以参考文章<a href="http://ethfans.org/posts/Merkle-Patricia-Tree">Merkle树</a></p>
</blockquote>

<p>3.<code>Bloom</code></p>

<p>区块头里的布隆过滤器是用于搜索收据而构建的。</p>

<blockquote>
  <p><a href="https://github.com/cpselvis/zhihu-crawler/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0">布隆过滤器</a></p>
</blockquote>

<h1 id="section-4">挖矿难度控制</h1>

<p>1.<code>Difficulty</code></p>

<p>以太坊的挖矿难度是动态调整的,它的难度调整仅和父区块和本区块挖矿时间有关。 而该函数实现里根据启动参数目前有三种难度调整方案:</p>

<p><code>go github.com/ethereum/go-ethereum/consensus/ethash/consensus.go
func CalcDifficulty(config *params.ChainConfig, time uint64, parent *types.Header) *big.Int {
    next := new(big.Int).Add(parent.Number, big1)
    switch {
    case config.IsByzantium(next):
        return calcDifficultyByzantium(time, parent)
    case config.IsHomestead(next):
        return calcDifficultyHomestead(time, parent)
    default:
        return calcDifficultyFrontier(time, parent)
    }
}
</code></p>

<p>每种策略代码这里不具体展开,总的来说难度值的计算是这样的:</p>

<p><code>
本区块难度 = 父区块难度 + 难度调整值 + 难度炸弹
难度调整值 = f(父区块难度,父区块产生时间,本区块产生时间)
难度炸弹 = 2^(区块号/100000 - 2)
</code></p>

<p>以太坊的区块难度以单个区块为单位进行调整，可以非常迅速的适应算力的变化，正是这种机制，使以太坊在硬分叉出以太坊经典(ETC)以后没有出现比特币分叉出比特币现金(BCC)后的算力“暴击”问题。同时，以太坊的新区块难度在老区块的基础上有限调整的机制也使区块难度不会出现非常大的跳变</p>

<p>从这个公式可以看出,区块难度短期内仅和难度调整值有关(因为难度炸弹只有每100000个区块才会产生跳变),但是当挖矿到5400000区块后,难度值跳变到非常大,这个时候就不再适合挖矿。 </p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/eth-diff.jpg" alt="eth-diff" /></p>

<h1 id="pow">PoW参数</h1>

<p>接下来的两个参数就和无人不知无人不晓的工作量证明息息相关了,以太坊的工作量证明最终拼的就是谁最先得到这两个参数:<code>MixDigest</code>和<code>Nonce</code>.</p>

<p>目前以太坊线上使用的共识算法是基于PoW的ethash算法,主要实现位于<code>github.com/ethereum/go-ethereum/consensus/ethash</code>包中。</p>

<p>PoW算法的思路都大致是相似的,通过暴力枚举猜测一个nonce值,使得根据这个nonce种子计算出的hash值符合约定的难度,这个难度其实就是要求hash值前缀包含多少个0. </p>

<p>目前以太坊使用的hash是256位,所以将难度折算成前缀0的位数就是:<code>bits0 = (2^256)/difficulty</code>,那么我们的代码不停枚举nonce然后将计算得到的hash值前缀0位数和这个做比较就行了,主逻辑代码如下:</p>

<p><code>go 
func (ethash *Ethash) mine(block *types.Block, id int, seed uint64, abort chan struct{}, found chan *types.Block) {
    // Extract some data from the header
    var (
        header  = block.Header()
        hash    = header.HashNoNonce().Bytes()
        // 将难度转换得出前缀0的位数
        target  = new(big.Int).Div(maxUint256, header.Difficulty)
        number  = header.Number.Uint64()
        dataset = ethash.dataset(number)
    )
    ...
search:
    for {
        ...
            // Compute the PoW value of this nonce
            digest, result := hashimotoFull(dataset.dataset, hash, nonce)
            if new(big.Int).SetBytes(result).Cmp(target) &lt;= 0 {
                // Correct nonce found, create a new header with it
                header = types.CopyHeader(header)
                header.Nonce = types.EncodeNonce(nonce)
                header.MixDigest = common.BytesToHash(digest)
                ...
            }
            nonce++
         ...
    }
}
</code></p>

<p>该函数首先计算出区块难度对应的前缀0位数<code>target</code>,然后生成PoW依赖的计算数据集<code>dataset = ethash.dataset(number)</code>,最终开始死循环尝试计算<code>digest, result := hashimotoFull(dataset.dataset, hash, nonce)</code>,得到结果后将这两个随机数据赋值到区块头对应字段去。</p>

<p>当这个区块成功挖出后，别的区块很容易验证这个区块的PoW是否有效,就使用同样方法产生计算数据集<code>dataset</code>,然后调用<code>hashimotoLight(和hashimotoFull基本一致)</code>计算出<code>digest</code>和区块头的<code>MixDigest</code>做比较就可以了。</p>

<p>这里我们跳过了两个重要的步骤:</p>

<p>a.依赖数据集<code>dataset</code>的生成实现
b.<code>hashimotoFull/hashimotoLight</code>的具体实现</p>

<p>依赖数据集的生成就要说到以太坊的DAG</p>

<h2 id="dag">DAG</h2>

<p>ethash将DAG（有向非循环图）用于工作量证明算法，这是为每个epoch(<code>epoch := block / epochLength</code>)生成，例如，每3000个区块（125个小时，大约5.2天）。DAG要花很长时间生成。如果客户端只是按需要生成它，那么在找到新epoch第一个区块之前，每个epoch过渡都要等待很长时间。然而，DAG只取决于区块数量，所以可以预先计算来避免在每个epoch过渡过长的等待时间。Geth和ethminer执行自动的DAG生成，每次维持2个DAG以便epoch过渡流畅。挖矿从控制台操控的时候，自动DAG生成会被打开和关闭。</p>

<h2 id="hashimoto">hashimoto</h2>

<blockquote>
  <p>下面的描述摘自<a href="http://blog.csdn.net/teaspring/article/details/78050274">挖矿和共识算法的奥秘</a></p>
</blockquote>

<p>hashimoto()的逻辑比较复杂，包含了多次、多种哈希运算。下面尝试从其中数据结构变化的角度来简单描述之：</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/consensus.png" alt="hashimoto" /></p>

<p>简单介绍一下上图所代表的代码流程：</p>

<ul>
  <li>首先，hashimoto()函数将入参@hash和@nonce合并成一个40 bytes长的数组，取它的SHA-512哈希值取名seed，长度为64 bytes。</li>
  <li>然后，将seed[]转化成以uint32为元素的数组mix[]，注意一个uint32数等于4 bytes，故而seed[]只能转化成16个uint32数，而mix[]数组长度32，所以此时mix[]数组前后各半是等值的。</li>
  <li>接着，lookup()函数登场。用一个循环，不断调用lookup()从外部数据集中取出uint32元素类型数组，向mix[]数组中混入未知的数据。循环的次数可用参数调节，目前设为64次。每次循环中，变化生成参数index，从而使得每次调用lookup()函数取出的数组都各不相同。这里混入数据的方式是一种类似向量“异或”的操作，来自于FNV算法。</li>
  <li>待混淆数据完成后，得到一个基本上面目全非的mix[]，长度为32的uint32数组。这时，将其折叠(压缩)成一个长度缩小成原长1/4的uint32数组，折叠的操作方法还是来自FNV算法。</li>
  <li>最后，将折叠后的mix[]由长度为8的uint32型数组直接转化成一个长度32的byte数组，这就是返回值@digest；同时将之前的seed[]数组与digest合并再取一次SHA-256哈希值，得到的长度32的byte数组，即返回值@result。</li>
</ul>

<p>最终经过一系列多次、多种的哈希运算，hashimoto()返回两个长度均为32的byte数组 - digest[]和result[]。回忆一下ethash.mine()函数中，对于hashimotoFull()的两个返回值，会直接以big.int整型数形式比较result和target；如果符合要求，则将digest取SHA3-256的哈希值(256 bits)，并存于Header.MixDigest中，待以后Ethash.VerifySeal()可以加以验证。</p>

<h1 id="section-5">其他</h1>

<p>1.<code>Extra</code></p>

<h1 id="section-6">参考文献</h1>

<ul>
  <li><a href="http://blog.csdn.net/teaspring/article/details/78050274">挖矿和共识算法的奥秘</a> </li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入ethereum源码-whisper协议解读]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/02/07/shen-ru-ethereumyuan-ma-whisperxie-yi-jie-du/"/>
    <updated>2018-02-07T16:13:02+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/02/07/shen-ru-ethereumyuan-ma-whisperxie-yi-jie-du</id>
    <content type="html"><![CDATA[<p>whisper协议是以太坊DApps之间的通信协议。</p>

<!-- more -->

<h1 id="section">概述</h1>

<p>whisper是完全基于<code>ID</code>的消息系统,它的设计目的是形成一套p2p节点间的异步广播系统。whisper网络上的消息是加密传送的,完全可以暴露在公网进行传输;此外,为了防范<code>DDos</code>攻击,whisper使用了<code>proof-of-work(PoW)</code>工作量证明提高消息发送门槛。</p>

<h1 id="whisper">whisper基础构件</h1>

<p>whisper协议对上层暴露出一套类似于<code>订阅-发布</code>的API模型,节点可以申请自己感兴趣的<code>topic</code>，那么就只会接收到这些<code>topic</code>的消息,无关主题的消息将被丢弃。在这套体系内，有几个基础构件需要说明下:</p>

<h2 id="envelope">Envelope信封</h2>

<p><code>envelope即信封</code>是whisper网络节点传输数据的基本形式。信封包含了加密的数据体和明文的元数据,元数据主要用于基本的消息校验和消息体的解密。</p>

<p>信封是以RLP编码的格式传输:</p>

<p><code>
[ Version, Expiry, TTL, Topic, AESNonce, Data, EnvNonce ]
</code></p>

<ul>
  <li><code>Version</code>:最多4字节(目前仅使用了1字节)，如果信封的<code>Version</code>比本节点当前值高,将无法解密,仅做转发</li>
  <li><code>Expiry</code>:4字节（unix时间戳秒数）,过期时间</li>
  <li><code>TTL</code>:4字节,剩余存活时间秒数</li>
  <li><code>Topic</code>:4字节,信封主题</li>
  <li><code>AESNonce</code>:12字节随机数据,仅在对称加密时有效</li>
  <li><code>Data</code>:消息体</li>
  <li><code>EnvNonce</code>:8字节任意数据(用于PoW计算)</li>
</ul>

<p>如果节点无法解密信封，那么节点对信封内的消息内容一无所知，单这并不影响节点将消息进行转发扩散。</p>

<h2 id="message">Message消息</h2>

<p>信封内的消息体解密后即得到消息内容。</p>

<h2 id="topic">Topic主题</h2>

<p>每个信封上都有一个主题,注意主题可以仅使用部分前缀</p>

<h2 id="filter">Filter过滤器</h2>

<p><code>filter</code>即<code>订阅-发布</code>模型中的订阅者</p>

<h2 id="pow">PoW工作量证明</h2>

<p><code>PoW</code>的存在是为了反垃圾信息以及降低网络负担。计算PoW所付出的代价可以理解为抵扣节点为传播和存储信息锁花费的资源.</p>

<p>在<code>whisperv5</code>中,<code>PoW</code>定义为:</p>

<p><code>
PoW = (2^BestBit) / (size * TTL)
</code></p>

<ul>
  <li><code>BestBit</code>是hash计算值的前导0个数</li>
  <li><code>size</code>是消息大小</li>
  <li><code>TTL</code></li>
</ul>

<p>具有高<code>PoW</code>的消息具有优先处理权。</p>

<p>whisper节点发送消息需要经过<code>创建消息whisper.NewSentMessage()</code>—-&gt;<code>封装入信封msg.Wrap(msg)</code>—-&gt;<code>shh.Send()</code>,消息的工作量证明就在第二步装入信封的时候进行计算。</p>

<p><code>Warp</code>函数最终调用<code>Seal</code>:</p>

<p>```go github.com/ethereum/go-ethereum/whisper/whisperv5/envelope.go
func (e *Envelope) Seal(options *MessageParams) error {
    var target, bestBit int // target是需要达到的目标前置0位数
    if options.PoW == 0 {
        // 将消息过期时间调整到工作量计算完成后
        e.Expiry += options.WorkTime
    } else {
        // 根据公式 PoW = (2^BestBit) / (size * TTL) 从预设的PoW阈值反解出BestBit
        target = e.powToFirstBit(options.PoW)
        if target &lt; 1 {
            target = 1
        }
    }</p>

<pre><code>buf := make([]byte, 64)
// Keccak256是SHA-3的一种,Keccak已可以抵御最小的复杂度为2n的攻击，其中N为散列的大小。它具有广泛的安全边际。至目前为止，第三方密码分析已经显示出Keccak没有严重的弱点
h := crypto.Keccak256(e.rlpWithoutNonce())
copy(buf[:32], h)

finish := time.Now().Add(time.Duration(options.WorkTime) * time.Second).UnixNano()
for nonce := uint64(0); time.Now().UnixNano() &lt; finish; {
    for i := 0; i &lt; 1024; i++ {
        // 暴力尝试nonce值
        binary.BigEndian.PutUint64(buf[56:], nonce)
        d := new(big.Int).SetBytes(crypto.Keccak256(buf))
        firstBit := math.FirstBitSet(d)
        if firstBit &gt; bestBit {
            e.EnvNonce, bestBit = nonce, firstBit
            // 当尝试得到满足条件的EnvNonce,计算完成
            if target &gt; 0 &amp;&amp; bestBit &gt;= target {
                return nil
            }
        }
        nonce++
    }
}
if target &gt; 0 &amp;&amp; bestBit &lt; target {
    return fmt.Errorf("failed to reach the PoW target, specified pow time (%d seconds) was insufficient", options.WorkTime)
}
return nil } ```
</code></pre>

<h1 id="section-1">通信流程</h1>

<p>whisper协议的实现位于包<code>github.com/ethereum/go-ethereum/whisper</code>，该包下面有多个版本实现,目前最新协议包是<code>whisperv6</code>.</p>

<h2 id="whisper-main-loop">whisper main loop</h2>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/whisper-main-loop.png" alt="whisper-main-loop" /></p>

<p>whisper节点启动后产生两个分支:</p>

<ul>
  <li>一个分支负责清理<code>shh.envelopes</code>中的过期消息</li>
  <li>另一个分支(proccessQueue)从两个队列取出新接收到的消息,根据消息对应topic投放(Trigger)到对应接收者(filter),从而交付给上层应用进行处理</li>
</ul>

<p>补充说下whisper里两个队列<code>messageQueue,p2pMsgQueue</code>的不同作用,<code>messageQueue</code>接收普通的广播消息,<code>p2pMsgQueue</code>接收点对点的直接消息,可绕过<code>pow</code>和<code>ttl</code>限制.</p>

<h2 id="whisper-protocol">whisper protocol</h2>

<p>whisper协议的具体实现里,代码流程也非常清晰:</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/whisper-peer-loop.png" alt="whisper-peer-loop" /></p>

<p>每个peer连接成功后,产生两个goroutine,进行消息接收和广播:</p>

<ul>
  <li>接收消息协程不断从连接中读取新消息,并且将消息暂存到<code>shh.envelopes</code>中,如果发现是一条未接收过的新消息,则将消息转发到对应的队列<code>(messageQueue,p2pMsgQueue)</code></li>
  <li>广播协程负责将该peer未接收过的消息(本节点认为该peer未接收过,并非peer一定没接收过,p2p网络其他节点可能已经将消息广播到该节点了)投递到该peer</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入ethereum源码-p2p模块节点发现机制]]></title>
    <link href="http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi/"/>
    <updated>2018-01-30T11:40:37+08:00</updated>
    <id>http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi</id>
    <content type="html"><![CDATA[<p>ethereum是基于kademlia协议实现其节点自动发现机制,完整整个网络拓扑关系的构建刷新。
<!-- more --></p>

<ul id="markdown-toc">
  <li><a href="#kademlia">Kademlia协议</a></li>
  <li><a href="#kademlia-like">以太坊Kademlia-like协议</a></li>
  <li><a href="#section">源码跟踪以太坊节点发现机制</a>    <ul>
      <li><a href="#refreshloop">1. <code>refreshLoop()</code></a></li>
      <li><a href="#loopreadloop">2. <code>loop()</code>和<code>readLoop()</code></a></li>
    </ul>
  </li>
  <li><a href="#section-1">内网穿透</a></li>
  <li><a href="#section-2">参考文献</a></li>
</ul>

<h1 id="kademlia">Kademlia协议</h1>

<blockquote>
  <p>以下内容摘自维基百科,全文查看参考文献Kademlia</p>
</blockquote>

<p>Kademlia是一种通过分散式杂凑表实现的协议算法，它是由Petar和David为非集中式P2P计算机网络而设计的。Kademlia规定了网络的结构，也规定了通过节点查询进行信息交换的方式。Kademlia网络节点之间使用UDP进行通讯。参与通讯的所有节点形成一张虚拟网（或者叫做覆盖网）。这些节点通过一组数字（或称为节点ID）来进行身份标识。节点ID不仅可以用来做身份标识，还可以用来进行值定位。</p>

<p>Kademlia路由表由多个列表组成，每个列表对应节点ID的一位（例如：假如节点ID共有128位，则节点的路由表将包含128个列表），包含多个条目，条目中包含定位其他节点所必要的一些数据。列表条目中的这些数据通常是由其他节点的IP地址，端口和节点ID组成。每个列表对应于与节点相距特定范围距离的一些节点，节点的第n个列表中所找到的节点的第n位与该节点的第n位肯定不同，而前n-1位相同，这就意味着很容易使用网络中远离该节点的一半节点来填充第一个列表（第一位不同的节点最多有一半），而用网络中四分之一的节点来填充第二个列表（比第一个列表中的那些节点离该节点更近一位），依次类推。如果ID有128个二进制位，则网络中的每个节点按照不同的异或距离把其他所有的节点分成了128类，ID的每一位对应于其中的一类。随着网络中的节点被某节点发现，它们被逐步加入到该节点的相应的列表中，这个过程中包括向节点列表中存信息和从节点列表中取信息的操作，甚至还包括当时协助其他节点寻找相应键对应值的操作。这个过程中发现的所有节点都将被加入到节点的列表之中，因此节点对整个网络的感知是动态的，这使得网络一直保持着频繁地更新，增强了抵御错误和攻击的能力。</p>

<p>在Kademlia相关的论文中，列表也称为K桶，其中K是一个系统变量，如20，每一个K桶是一个最多包含K个条目的列表，也就是说，网络中所有节点的一个列表（对应于某一位，与该节点相距一个特定的距离）最多包含20个节点。随着对应的bit位变低（即对应的异或距离越来越短），K桶包含的可能节点数迅速下降（这是由于K桶对应的异或距离越近，节点数越少），因此，对应于更低bit位的K桶显然包含网络中所有相关部分的节点。由于网络中节点的实际数量远远小于可能ID号的数量，所以对应那些短距离的某些K桶可能一直是空的（如果异或距离只有1，可能的数量就最大只能为1，这个异或距离为1的节点如果没有发现，则对应于异或距离为1的K桶则是空的）。</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/63/Dht_example_SVG.svg" alt="kademlia example" /></p>

<p>让我们看上面的那个简单网络，该网络最大可有2^3，即8个关键字和节点，目前共有7个节点加入，每个节点用一个小圈表示（在树的底部）。我们考虑那个用黑圈标注的节点6，它共有3个K桶，节点0，1和2（二进制表示为000，001和010）是第一个K桶的候选节点，节点3目前（二进制表示为011）还没有加入网络，节点4和节点5（二进制表示分别为100和101）是第二个K桶的候选节点，只有节点7（二进制表示为111）是第3个K桶的候选节点。图中，3个K桶都用灰色圈表示，假如K桶的大小（即K值）是2，那么第一个K桶只能包含3个节点中的2个。众所周知，那些长时间在线连接的节点未来长时间在线的可能性更大，基于这种静态统计分布的规律，Kademlia选择把那些长时间在线的节点存入K桶，这一方法增长了未来某一时刻有效节点的数量，同时也提供了更为稳定的网络。当某个K桶已满，而又发现了相应于该桶的新节点的时候，那么，就首先检查K桶中最早访问的节点，假如该节点仍然存活，那么新节点就被安排到一个附属列表中（作为一个替代缓存）.只有当K桶中的某个节点停止响应的时候，替代cache才被使用。换句话说，新发现的节点只有在老的节点消失后才被使用。</p>

<h1 id="kademlia-like">以太坊Kademlia-like协议</h1>

<p>以太坊的kademlia网(简称kad)和标准kad网有部分差异.</p>

<p>下面对照以太坊源码,阐述下kad网里几个概念:</p>

<p><code>go github.com/ethereum/go-ethereum/p2p/discover/table.go
const (
    alpha      = 3                      // Kademlia并发参数
    bucketSize = 16                     // Kademlia K桶大小(可容纳节点数)
    hashBits   = len(common.Hash{}) * 8 // 每个节点ID长度,32*8=256, 32位16进制
    nBuckets   = hashBits + 1           // K桶个数
)
</code></p>

<ul>
  <li><code>α</code>即代码里的<code>alpha</code>,是系统内一个优化参数,控制每次从K桶最多取出节点个数,ethereum取值3</li>
  <li><code>bucketSize</code>,K桶大小,ethereum取16</li>
  <li><code>hashBits</code>,节点长度256位</li>
  <li><code>nBuckets</code>,K桶个数,目前取257</li>
</ul>

<p>以太坊Kad网总共定义了4种消息类型:</p>

<p>```go github.com/ethereum/go-ethereum/p2p/discover/udp.go
const (
    pingPacket = iota + 1 // ping操作
    pongPacket            // pong操作</p>

<pre><code>findnodePacket        // find node节点查询
neighborsPacket       // neighbors邻居回应 ) ```
</code></pre>

<p><code>ping</code>和<code>pong</code>是一对操作,用于检测节点活性,节点收到<code>ping</code>消息后立即回复<code>pong</code>响应:</p>

<p><code>go
// 收到ping消息的响应函数
func (req *ping) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {
    ...
    // 向ping消息发送方回复pong
    t.send(from, pongPacket, &amp;pong{
        To:         makeEndpoint(from, req.From.TCP),
        ReplyTok:   mac,
        Expiration: uint64(time.Now().Add(expiration).Unix()),
    })
    if !t.handleReply(fromID, pingPacket, req) {
        // 成功完成一次ping-pong,更新K桶节点信息
        go t.bond(true, fromID, from, req.From.TCP)
    }
    return nil
}
</code></p>

<p><code>findnode</code>和<code>neighbors</code>是一对操作.</p>

<p><code>findnode</code>用于查找与某节点相距最近的节点,查找到后以<code>neighbors</code>类型消息回复查找发起者</p>

<p>```go
// 收到findnode消息的响应函数
func (req *findnode) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {
    …
    target := crypto.Keccak256Hash(req.Target[:])
    …
    // 从本节点路由表里查找于target节点相距最近的bucketSize的节点
    closest := t.closest(target, bucketSize).entries
    …</p>

<pre><code>p := neighbors{Expiration: uint64(time.Now().Add(expiration).Unix())}
// 回复查询发起方
for i, n := range closest {
    ...
    t.send(from, neighborsPacket, &amp;p)
    ...
}
return nil } ```
</code></pre>

<h1 id="section">源码跟踪以太坊节点发现机制</h1>

<p>了解了以太坊的4种基本操作以及kad网络概念,我们就可以来看看节点发现机制怎么流转起来的:</p>

<p>节点发现的代码位于<code>github.com/ethereum/go-ethereum/p2p/discover</code>包。</p>

<p>首先,在节点启动时启动UDP”端口监听”:<code>server.Start() ==&gt; discover.ListenUDP ==&gt; newUDP()</code></p>

<p><code>newUDP()</code>分叉出去三个流程,三个流程均是无限循环:</p>

<ul>
  <li><code>func (tab *Table) refreshLoop()</code></li>
  <li><code>func (t *udp) loop()</code></li>
  <li><code>func (t *udp) readLoop(unhandled chan ReadPacket)</code></li>
</ul>

<h4 id="refreshloop">1. <code>refreshLoop()</code></h4>

<p>该流程每隔1小时或按需刷新K桶,核心逻辑实现位于<code>doRefresh</code>函数:</p>

<p>```go github.com/ethereum/go-ethereum/p2p/discover/table.go
func (tab *Table) doRefresh(done chan struct{}) {
    …
    // 和标准Kademlia协议选取最旧的K桶进行刷新不同，以太坊选取一个随机节点ID作为刷新基点
    var target NodeID
    rand.Read(target[:])
    // lookup函数是最kad网最核心函数,查询离target最近一批节点
    result := tab.lookup(target, false)
    if len(result) &gt; 0 {
        return
    }</p>

<pre><code>// 如果没找到,则从本地节点数据库加载预配置的种子节点到对应K桶
seeds := tab.db.querySeeds(seedCount, seedMaxAge)
seeds = tab.bondall(append(seeds, tab.nursery...))
...
// 最后,以自身作为目标节点,刷新K桶
tab.lookup(tab.self.ID, false) } ```
</code></pre>

<p><code>tab.lookup</code>函数虽然关键,然而其逻辑其实是很简单的:</p>

<p>a. 查询离target最近一批节点,距离计算即对kad网络XOR(异或)距离计算的实现</p>

<p><code>go
func (tab *Table) closest(target common.Hash, nresults int) *nodesByDistance {
    // 遍历本地路由节点表
    close := &amp;nodesByDistance{target: target}
    for _, b := range tab.buckets {
        for _, n := range b.entries {
            close.push(n, nresults)
        }
    }
    return close
}
// close.push最终调用distcmp进行异或计算
func distcmp(target, a, b common.Hash) int {
    for i := range target {
        da := a[i] ^ target[i]
        db := b[i] ^ target[i]
        if da &gt; db {
            return 1
        } else if da &lt; db {
            return -1
        }
    }
    return 0
}
</code></p>

<p>b. 迭代上一步查到的所有节点,向这些节点发起<code>findnode</code>操作查询离target节点最近的节点列表,将查询得到的节点进行<code>ping-pong</code>测试,将测试通过的节点落库保存</p>

<p>经过这个流程后,节点的K桶就能够比较均匀地将不同网络节点更新到本地K桶中。</p>

<h4 id="loopreadloop">2. <code>loop()</code>和<code>readLoop()</code></h4>

<p>这两个循环流程放在一起说,它们主要是一个工程实现,将异步调用代码通过channel串接成同步。业务上主要是负责处理<code>ping,pong,findnode,neighbors</code>四个消息类型的收发。</p>

<p>唯一值得稍加阐述的可能只有<code>pending</code>结构:</p>

<p>```go
// pending实现了一种延迟处理逻辑
//
// 它主要有两个作用:
// 1. 提供回调机制,当某一个操作发起异步请求时,就使用pending结构封装一个闭包,当收到异步回复后从pending列表取出这个闭包,执行回调,因此在这个回调里可以完成数据包校验等后处理
// 如findnode操作将更新k桶的操作暂存,再获取到异步回复后执行这个闭包完成k桶更新
// 2. 提供多个回复接收功能,一个RPC请求可能会对应多个回复包,比如findnode对应多个neigbours回复包,此时可以提供多个pending进行逐个包校验
type pending struct {
    // 来源节点
    from  NodeID
    ptype byte</p>

<pre><code>// 调用超时丢弃pending结构
deadline time.Time

// 回调函数,简单而强大
callback func(resp interface{}) (done bool)

errc chan&lt;- error } ```
</code></pre>

<p>综述,邻居节点发现流程:</p>

<p><img src="https://raw.githubusercontent.com/qjpcpu/qjpcpu.github.com/master/images/eth_kad.jpeg" alt="kademlia" /></p>

<p>节点第一次启动读取公共种子节点信息,已本节点ID作为target更新本地K桶,然后每隔一段时间进行节点更新, 刷新K桶流程如下:</p>

<p>a. 随机生成目标节点Id，记为TargetId，从1开始记录发现次数和刷新时间。</p>

<p>b. 在当前节点的K桶里查找与目标节点最近的16个节点</p>

<p>c. 向b中得到的每个节点发送findnode命令,接收到每个节点传回的neighbours节点</p>

<p>d. 对c返回的每个节点进行ping-pong测试然后更新到本地k桶</p>

<p>e. 上述流程均是基于UDP的发现流程,p2p网络会定时随机取k桶中未连接的节点进行TCP连接,在连接好的TCP通道进行通信(tcp连接协程里会自己做心跳维护这个连接)</p>

<h1 id="section-1">内网穿透</h1>

<p>ethereum是基于p2p通信的,所有的操作都有可能涉及到内网穿透,而目前内网穿透最常用的方法是udp打洞,这也是kad网络使用udp作为基础通信协议的原因。</p>

<p>一个简单的udp打通进行p2p通信的例子讲解可以参考<a href="http://qjpcpu.github.io/blog/2018/01/29/shen-ru-ethereumyuan-ma-p2pmo-kuai-ji-chu-jie-gou/">深入ethereum源码-p2p模块基础结构</a>。</p>

<p>然而以太坊里将这部分逻辑全部隐藏,可以在节点初始化函数里看出一点痕迹:</p>

<p><code>go 
func (srv *Server) Start() (err error) {
        addr, err := net.ResolveUDPAddr("udp", srv.ListenAddr)
        if err != nil {
            return err
        }
        conn, err = net.ListenUDP("udp", addr)
        if err != nil {
            return err
        }
        realaddr = conn.LocalAddr().(*net.UDPAddr)
        if srv.NAT != nil {
            if !realaddr.IP.IsLoopback() {
                // 进行内网网端口映射
                go nat.Map(srv.NAT, srv.quit, "udp", realaddr.Port, realaddr.Port, "ethereum discovery")
            }
            // TODO: react to external IP changes over time.
            if ext, err := srv.NAT.ExternalIP(); err == nil {
                realaddr = &amp;net.UDPAddr{IP: ext, Port: realaddr.Port}
            }
        }
}
</code></p>

<p>首先，以太坊tcp/udp共用了一个端口,然后使用uPnp协议簇进行内外网端口映射,完成链路打通,从而穿透内网.</p>

<p>具体封装位于<code>nat</code>模块,但具体实现也是使用了三方库<a href="https://github.com/huin/goupnp">goupnp</a>.具体实现是关于uPnP的一个大话题,就不在这里分叉出去了。</p>

<h1 id="section-2">参考文献</h1>

<ul>
  <li><a href="https://zh.wikipedia.org/wiki/Kademlia">Kademlia</a></li>
  <li><a href="http://www.yeolar.com/note/2010/03/21/kademlia/">Kademlia协议原理简介</a></li>
  <li><a href="https://github.com/ethereum/wiki/wiki/Node-discovery-protocol">Node discovery protocol</a></li>
  <li><a href="http://www.8btc.com/etc-p2p">P2P网络及节点发现机制</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
