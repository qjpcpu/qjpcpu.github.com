
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>初识hadoop及map-reduce - Jason's space</title>
	<meta name="author" content="Jason">

	
	<meta name="description" content="搭建hadoop环境 hadoop环境搭建具体可以参考官方文档。 搭建配置maven map-reduce任务支持多种语言，但对java支持是最好的，所以这里说一下怎么搭建java的编译环境。 首先编译安装maven，并将MAVEN_HOME/bin加入PATH环境变量， &hellip;">
	
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script async="true" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-113796486-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-113796486-1');
</script>

</head>


<body>
	<header id="header" class="inner"><h1><a href="/">Jason's space</a></h1>
<nav id="main-nav"><ul class="main">
	<li><a href="/blog/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
	<li><a href="/blog/categories">Categories</a></li>
	<li><a href="/about">About</a></li>
</ul>

</nav>
<!--
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul class="main">
	<li><a href="/blog/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
	<li><a href="/blog/categories">Categories</a></li>
	<li><a href="/about">About</a></li>
</ul>

</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:qjpcpu.github.io">
			</form>
		</div>
	</div>
</nav>
<nav id="sub-nav" class="alignright">
	<div class="social">
		
		
		
		
    
		
		
		
		
		
		<a class="rss" href="/atom.xml" title="RSS">RSS</a>
		
    
	</div>
	<form class="search" action="/search.html" method="get">
		<input class="search" type="text" name="query" x-webkit-speech/>
	</form>
</nav>
-->

</header>
	
		
	
	<div id="content" class="inner"><article class="post">
	<h2 class="title">初识hadoop及map-reduce</h2>
	<div class="entry-content"><h2 id="hadoop">搭建hadoop环境</h2>

<p>hadoop环境搭建具体可以参考<a href="http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html">官方文档</a>。</p>

<h2 id="maven">搭建配置maven</h2>

<p>map-reduce任务支持多种语言，但对java支持是最好的，所以这里说一下怎么搭建java的编译环境。</p>

<p>首先编译安装maven，并将<code>MAVEN_HOME/bin</code>加入PATH环境变量，这样就可以直接使用<code>mvn</code>命令了。这里说一下怎么利用maven编译生成我们后续示例中的jar包。</p>

<h3 id="maven-1">1. 使用maven新建一个工程</h3>

<p>下面的命令创建一个包含java类<code>org.myorg.WordCount</code>的工程<code>WordCount</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">mvn archetype:create -DgroupId<span class="o">=</span>org.myorg -DartifactId<span class="o">=</span>WordCount
</span></code></pre></td></tr></table></div></figure></notextile></div>
<!--more-->

<p>工程结构如图：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">WordCount
</span><span class="line">├── pom.xml
</span><span class="line">└── src
</span><span class="line">    ├── main
</span><span class="line">    │   └── java
</span><span class="line">    │       └── org
</span><span class="line">    │           └── myorg
</span><span class="line">    │               └── App.java
</span><span class="line">    └── <span class="nb">test</span>
</span><span class="line">        └── java
</span><span class="line">            └── org
</span><span class="line">                └── myorg
</span><span class="line">                    └── AppTest.java
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>将<code>WordCount/src/main/java/org/myorg/App.java</code>重命名为<code>WordCount/src/main/java/org/myorg/WordCount.java</code>，并将示例代码复制进去，代码的细节稍后再看。</p>

<p>由于java类中依赖于hadoop的java包，所以在maven的配置文件<code>pom.xml</code>标签对<code>&lt;dependencies/&gt;</code>内添加java类文件里引用的依赖：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>WordCount/pom.xml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="xml"><span class="line"><span class="nt">&lt;dependency&gt;</span>
</span><span class="line">  <span class="nt">&lt;groupId&gt;</span>org.apache.hadoop<span class="nt">&lt;/groupId&gt;</span>
</span><span class="line">  <span class="nt">&lt;artifactId&gt;</span>hadoop-mapreduce-client-core<span class="nt">&lt;/artifactId&gt;</span>
</span><span class="line">  <span class="nt">&lt;version&gt;</span>2.4.1<span class="nt">&lt;/version&gt;</span>
</span><span class="line"><span class="nt">&lt;/dependency&gt;</span>
</span><span class="line"><span class="nt">&lt;dependency&gt;</span>
</span><span class="line">  <span class="nt">&lt;groupId&gt;</span>org.apache.hadoop<span class="nt">&lt;/groupId&gt;</span>
</span><span class="line">  <span class="nt">&lt;artifactId&gt;</span>hadoop-common<span class="nt">&lt;/artifactId&gt;</span>
</span><span class="line">  <span class="nt">&lt;version&gt;</span>2.4.1<span class="nt">&lt;/version&gt;</span>
</span><span class="line"><span class="nt">&lt;/dependency&gt;</span>
</span><span class="line"><span class="nt">&lt;dependency&gt;</span>
</span><span class="line">  <span class="nt">&lt;groupId&gt;</span>org.apache.hadoop<span class="nt">&lt;/groupId&gt;</span>
</span><span class="line">  <span class="nt">&lt;artifactId&gt;</span>hadoop-mapreduce-client-common<span class="nt">&lt;/artifactId&gt;</span>
</span><span class="line">  <span class="nt">&lt;version&gt;</span>2.4.1<span class="nt">&lt;/version&gt;</span>
</span><span class="line"><span class="nt">&lt;/dependency&gt;</span>
</span><span class="line"><span class="nt">&lt;dependency&gt;</span>
</span><span class="line">  <span class="nt">&lt;groupId&gt;</span>org.apache.hadoop<span class="nt">&lt;/groupId&gt;</span>
</span><span class="line">  <span class="nt">&lt;artifactId&gt;</span>hadoop-mapreduce-client-jobclient<span class="nt">&lt;/artifactId&gt;</span>
</span><span class="line">  <span class="nt">&lt;version&gt;</span>2.4.1<span class="nt">&lt;/version&gt;</span>
</span><span class="line"><span class="nt">&lt;/dependency&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="jar">2.编译生成jar包</h3>

<p>在WordCount根目录下执行：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">mvn package
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>就生成了我们需要的<code>WordCount/target/WordCount-1.0-SNAPSHOT.jar</code>文件。</p>

<h2 id="wordcount">执行示例程序WordCount</h2>

<p>示例程序是一个单词计数程序，输入文件有两个：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nv">file01</span>
</span><span class="line"><span class="o">=======================</span>
</span><span class="line">Hello World Bye World
</span><span class="line">
</span><span class="line"><span class="nv">file02</span>
</span><span class="line"><span class="o">=======================</span>
</span><span class="line">Hello Hadoop Goodbye Hadoop
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>### 1.上传数据文件</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c">#创建目录</span>
</span><span class="line">hdfs dfs -mkdir /user
</span><span class="line">hdfs dfs -mkdir /user/hadoop
</span><span class="line"><span class="c">#上传文件</span>
</span><span class="line">hdfs dfs -put file01 /user/hadoop/input
</span><span class="line">hdfs dfs -put file02 /user/hadoop/input
</span><span class="line"><span class="c">#查看文件是否上传上去了</span>
</span><span class="line">hdfs dfs -ls /user/hadoop/input
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="map-reduce">2.提交并执行map-reduce任务</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">hadoop jar WordCount-1.0-SNAPSHOT.jar org.myorg.WordCount /user/hadoop/input /user/hadoop/output
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="section">3.获取结果</h3>

<p>当任务执行完毕在输出目录会生成_SUCCESS文件：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">hdfs dfs -ls /user/hadoop/output
</span><span class="line"><span class="c">#输出是：</span>
</span><span class="line">-rw-r--r--   1 hadoop supergroup          0 2014-09-03 20:20 /user/hadoop/output/_SUCCESS
</span><span class="line">-rw-r--r--   1 hadoop supergroup         41 2014-09-03 20:20 /user/hadoop/output/part-00000
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>查看结果：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">hdfs dfs -cat /user/hadoop/output/part-00000
</span><span class="line"><span class="c">#输出：</span>
</span><span class="line">Bye	1
</span><span class="line">Goodbye	1
</span><span class="line">Hadoop	2
</span><span class="line">Hello	2
</span><span class="line">World	2
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="map-reduce-1">Map-Reduce</h2>

<p>回过头来再看执行map-reduce的这个java类<code>WordCount.java</code>，该类包含了两个静态内部类<code>Map</code>和<code>Reduce</code>，都继承了<code>MapReduceBase</code>基类，并各自实现了<code>Mapper</code>和<code>Reducer</code>接口。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>WordCount/src/main/java/org/myorg/WordCount.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
<span class="line-number">56</span>
<span class="line-number">57</span>
<span class="line-number">58</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kn">package</span> <span class="n">org</span><span class="o">.</span><span class="na">myorg</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">java.util.*</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.Path</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.conf.*</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.io.*</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.*</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.util.*</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordCount</span> <span class="o">{</span>
</span><span class="line"><span class="c1">//执行map操作的静态类</span>
</span><span class="line">    <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Map</span> <span class="kd">extends</span> <span class="n">MapReduceBase</span> <span class="kd">implements</span> <span class="n">Mapper</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class="line">	<span class="kd">private</span> <span class="kd">final</span> <span class="kd">static</span> <span class="n">IntWritable</span> <span class="n">one</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
</span><span class="line">	<span class="kd">private</span> <span class="n">Text</span> <span class="n">word</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">();</span>
</span><span class="line">
</span><span class="line">	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">map</span><span class="o">(</span><span class="n">LongWritable</span> <span class="n">key</span><span class="o">,</span> <span class="n">Text</span> <span class="n">value</span><span class="o">,</span> <span class="n">OutputCollector</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">output</span><span class="o">,</span> <span class="n">Reporter</span> <span class="n">reporter</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">	    <span class="n">String</span> <span class="n">line</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="na">toString</span><span class="o">();</span>
</span><span class="line">	    <span class="n">StringTokenizer</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringTokenizer</span><span class="o">(</span><span class="n">line</span><span class="o">);</span>
</span><span class="line">	    <span class="k">while</span> <span class="o">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="na">hasMoreTokens</span><span class="o">())</span> <span class="o">{</span>
</span><span class="line">		<span class="n">word</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="na">nextToken</span><span class="o">());</span>
</span><span class="line">		<span class="c1">//OutputCollector以单词本身为键，出现次数为键值进行计数，这里每出现一次计数1</span>
</span><span class="line">		<span class="n">output</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="n">one</span><span class="o">);</span>
</span><span class="line">	    <span class="o">}</span>
</span><span class="line">	<span class="o">}</span>
</span><span class="line">    <span class="o">}</span>
</span><span class="line"><span class="c1">//执行reduce操作的静态类</span>
</span><span class="line">    <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Reduce</span> <span class="kd">extends</span> <span class="n">MapReduceBase</span> <span class="kd">implements</span> <span class="n">Reducer</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class="line">	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">reduce</span><span class="o">(</span><span class="n">Text</span> <span class="n">key</span><span class="o">,</span> <span class="n">Iterator</span><span class="o">&lt;</span><span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">values</span><span class="o">,</span> <span class="n">OutputCollector</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">output</span><span class="o">,</span> <span class="n">Reporter</span> <span class="n">reporter</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">	    <span class="c1">//map后的结果是同一个key对应一个value的列表，所以这里遍历values迭代器，累加所有值，即得到每个单词计数值</span>
</span><span class="line">	    <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
</span><span class="line">	    <span class="k">while</span> <span class="o">(</span><span class="n">values</span><span class="o">.</span><span class="na">hasNext</span><span class="o">())</span> <span class="o">{</span>
</span><span class="line">		<span class="n">sum</span> <span class="o">+=</span> <span class="n">values</span><span class="o">.</span><span class="na">next</span><span class="o">().</span><span class="na">get</span><span class="o">();</span>
</span><span class="line">	    <span class="o">}</span>
</span><span class="line">	    <span class="n">output</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="o">(</span><span class="n">sum</span><span class="o">));</span>
</span><span class="line">	<span class="o">}</span>
</span><span class="line">    <span class="o">}</span>
</span><span class="line">    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class="line">	<span class="n">JobConf</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">JobConf</span><span class="o">(</span><span class="n">WordCount</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setJobName</span><span class="o">(</span><span class="s">&quot;wordcount&quot;</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setOutputKeyClass</span><span class="o">(</span><span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setOutputValueClass</span><span class="o">(</span><span class="n">IntWritable</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setMapperClass</span><span class="o">(</span><span class="n">Map</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setCombinerClass</span><span class="o">(</span><span class="n">Reduce</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setReducerClass</span><span class="o">(</span><span class="n">Reduce</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setInputFormat</span><span class="o">(</span><span class="n">TextInputFormat</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">	<span class="n">conf</span><span class="o">.</span><span class="na">setOutputFormat</span><span class="o">(</span><span class="n">TextOutputFormat</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">	<span class="n">FileInputFormat</span><span class="o">.</span><span class="na">setInputPaths</span><span class="o">(</span><span class="n">conf</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">]));</span>
</span><span class="line">	<span class="n">FileOutputFormat</span><span class="o">.</span><span class="na">setOutputPath</span><span class="o">(</span><span class="n">conf</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">args</span><span class="o">[</span><span class="mi">1</span><span class="o">]));</span>
</span><span class="line">
</span><span class="line">	<span class="n">JobClient</span><span class="o">.</span><span class="na">runJob</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
</span><span class="line">    <span class="o">}</span>
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>Mapper</code>接口是一个泛型接口,该接口4个参数分别指定了map方法的<code>输入键值，输入值，输出键值，输出值</code>类型。 类似的<code>Reducer</code>接口也是个泛型接口，它的前两个参数和map的后两个参数类型对应，从而也间接决定了后两个参数的类型。</p>

<p>简而言之，map的过程是把一行行的输入变成：</p>

<p>key1 =&gt; val1</p>

<p>key2 =&gt; val2</p>

<p>key3 =&gt; val1</p>

<p>而reduce的输入是排序过后map的输出：</p>

<p>key1 =&gt; [val1,val…..]</p>

<p>key2 =&gt; [val2,val…..]</p>

<p>…</p>

<p>reduce的操作就是把这个输入合并成我们想要的东西。</p>

<p>最后，<code>WordCount</code>类的<code>main</code>方法里设置输入输出，然后执行任务。</p>

<h2 id="streamingmap-reduce">以streaming方式执行map-reduce任务</h2>

<p>通常来说，简单的map-reduce任务还是用脚本来写比较快，比如ruby,python或者linux shell，这里使用bash来重写一次这个单词计数。</p>

<h3 id="map">1. map程序</h3>

<p>hadoop的streaming是流式处理，即上一操作的输入作为下一操作的输出，基本可以等价用管道来看：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">cat data-file | mapper.sh | sort | reducer.sh
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>输入输出都是走的标准输入输出，所以改写的map程序非常简单：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>map.sh map操作</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">awk <span class="s1">&#39;{for(i=1;i&lt;=NF;i++) print $i&quot; 1&quot;}&#39;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="reduce">2. reduce程序</h3>

<p>类似的重写reduce：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>reduce.sh  reduce操作</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">awk <span class="s1">&#39;{arr[$1]+=1}END{for(k in arr) print k&quot; &quot;arr[k]}&#39;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="streaming">3. 提交streaming任务</h3>

<p>提交streaming类型的任务需要指定一个额外的jar包<code>$HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.4.1.jar</code>，还要在命令里指出map和recude的脚本</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">hadoop jar <span class="nv">$HADOOP_HOME</span>/share/hadoop/tools/lib/hadoop-streaming-2.4.1.jar  -input <span class="s1">&#39;/user/hadoop/input/*&#39;</span> -output <span class="s1">&#39;/user/hadoop/output1&#39;</span> -mapper map.sh -reducer reduce.sh
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>任务执行的结果和之前是一致的：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">hdfs dfs -cat /user/hadoop/output1/part-00000
</span><span class="line"><span class="c">#输出:</span>
</span><span class="line">Hadoop 2
</span><span class="line">Goodbye 1
</span><span class="line">Bye 1
</span><span class="line">Hello 2
</span><span class="line">World 2
</span></code></pre></td></tr></table></div></figure></notextile></div>
</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-09-03T20:40:36+08:00" pubdate data-updated="true">Sep 3<span>rd</span>, 2014</time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/hadoop/'>hadoop</a>


</div>
	
	<div class="comments"><a href="#disqus_thread">Comments</a></div>
	
</div>
</article>

	<div class="share">
	<div class="addthis_toolbox addthis_default_style ">
		
		
		<a class="addthis_button_tweet"></a>
		
		
		
	</div>
	
</div>



<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2018

    Jason

</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'qjpcpugithubio';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://qjpcpu.github.io/blog/2014/09/03/chu-shi-hadoopji-map-reduce/';
        var disqus_url = 'http://qjpcpu.github.io/blog/2014/09/03/chu-shi-hadoopji-map-reduce/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//go.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>





</body>
</html>